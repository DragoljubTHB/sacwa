\documentclass[
12pt,
english,
ngerman,
headsepline,
twoside,
openright,
numbers=noenddot,version=first
]{scrreprt}

\usepackage{lmodern}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=2.75cm,headheight=1cm,headsep=0.666cm,footskip=1cm}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\setlength{\parskip}{\medskipamount}
\setlength{\parindent}{0pt}

\usepackage{babel}

%% include jabref file
\usepackage{caption}
\usepackage{cite}
\usepackage{courier}
\usepackage{color}
\usepackage{emptypage}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
%\usepackage{listings} doppelt
\usepackage[printonlyused]{acronym}
%\usepackage{svg}
\usepackage[acronym]{glossaries}
\usepackage{verbatim}
\usepackage{url}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{color}
\usepackage{csquotes}
\usepackage{totcount}
\usepackage{csvsimple}
\usepackage{amsmath}
\usepackage{rotating}
\usepackage{adjustbox}
\usepackage{tabulary}
\usepackage{lscape}
\usepackage[nomargin,inline,marginclue,draft]{fixme}
\usepackage{wrapfig}
%\usepackage{minted}
%\usepackage{fontspec}

\regtotcounter{chapter}

\setstretch{1.4}
\usepackage[unicode=true,
bookmarks=true,bookmarksnumbered=false,bookmarksopen=true,bookmarksopenlevel=2,
breaklinks=false,pdfborder={0 0 0},backref=false,colorlinks=false]
{hyperref}
\hypersetup{pdftitle={Serverless Architekturen für konventionelle Webanwendungen},
pdfauthor={Dragoljub Milasinovic}}

\makeatletter

% custom colors
\definecolor{lightergray}{gray}{0.95}
\definecolor{lighterergray}{gray}{0.98}

\DeclareCaptionFont{darkgray}{\color{darkgray}}
\DeclareCaptionFont{black}{\color{black}}
\DeclareCaptionFormat{listing}{\colorbox{lightergray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{
font=sf
,format=listing
,margin=0pt
,labelfont=darkgray
,textfont=black}

\lstset{
basicstyle=\scriptsize\ttfamily,
tabsize=2,
extendedchars=true,
breaklines=true,
frame=bt,
framesep=4pt,
keywordstyle=\color{blue}\ttfamily,
%keywordstyle=\color{violet}\bfseries,
stringstyle=\color{red}\ttfamily,
%stringstyle=\color{black}\ttfamily,
commentstyle=\color{ForestGreen}\ttfamily,
%commentstyle=\color{darkgray},
rulecolor=\color{lightergray},
backgroundcolor=\color{lighterergray},
showspaces=false,
showtabs=false,
xleftmargin=17pt,
numbersep=5pt,
numberstyle=\tiny,
numbers=left,
resetmargins=true,
framexleftmargin=17pt,
framexrightmargin=6pt,
framexbottommargin=4pt,
showstringspaces=false,
morekeywords={__global__},
columns=flexible
}

\lstloadlanguages{
Java, Bash, C++
}

% create css listing style
\lstdefinelanguage{JavaScript}{
keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
keywordstyle=\color{blue}\bfseries,
ndkeywords={class, export, boolean, throw, implements, import, this},
ndkeywordstyle=\color{darkgray}\bfseries,
identifierstyle=\color{black},
sensitive=false,
comment=[l]{//},
morecomment=[s]{/*}{*/},
commentstyle=\color{black}\ttfamily,
stringstyle=\color{black}\ttfamily,
morestring=[b]',
morestring=[b]"
}

% create css listing style
\lstdefinelanguage{Groovy}{
keywords={as, assert, break, case, catch ,class,const,continue,def,default,do,else,enum,extends
,false,finally,for,goto,if,implements,import,in,instanceof,interface,new,null,package,return,super
,switch,this,throw,throws,trait,true,try,while},
keywordstyle=\color{Black}\bfseries,
ndkeywords={shadowJar, class, boolean, throw, implements, import, this},
ndkeywordstyle=\color{darkgray}\bfseries,
identifierstyle=\color{black},
sensitive=false,
comment=[l]{//},
morecomment=[s]{/*}{*/},
commentstyle=\color{purple}\ttfamily,
stringstyle=\color{gray}\ttfamily,
morestring=[b]',
morestring=[b]"
}


\newcommand{\qq}{\symbol{34}} % 34 is the decimal ascii code for "
\newcommand\invisiblesection[1]{%
\refstepcounter{section}%
\addcontentsline{toc}{section}{\protect\numberline{\thesection}#1}%
\sectionmark{#1}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newenvironment{lyxcode}
{\par\begin{list}{}{
\setlength{\rightmargin}{\leftmargin}
\setlength{\listparindent}{0pt}% needed for AMS classes
\raggedright
\setlength{\itemsep}{0pt}
\setlength{\parsep}{0pt}
\normalfont\ttfamily}%
\item[]}
{\end{list}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%% Flexibles Seitenlayout
\usepackage[automark]{scrpage2}

%% Mehrspaltenlayout ermöglichen
\usepackage{multicol}

%% Unterstützung für Farben
\usepackage{color}

%% Schönere Tabellen
\usepackage{booktabs, longtable}

%% Schönerer Blocksatz
\usepackage{microtype}


%% Mehr Platz zwischen Überschrift und Tabelle
\newcommand{\@ldtable}{}
\let\@ldtable\table
\renewcommand{\table}{ %
\setlength{\@tempdima}{\abovecaptionskip} %
\setlength{\abovecaptionskip}{\belowcaptionskip} %
\setlength{\belowcaptionskip}{\@tempdima} %
\@ldtable %
}

%% Verschiedene Symbole und Zeichen wie (c)
\usepackage{textcomp}

%% Deutsche Kurzfassung und englisches Abstract auf eine Seite
\renewenvironment{abstract}{
\@beginparpenalty\@lowpenalty
\begin{center}
\normalfont\sectfont\nobreak\abstractname
\end{center}
\@endparpenalty\@M
}{
\par
}

%% Alle Seiten vor dem Inhaltsverzeichnis sind römisch nummeriert
\pagenumbering{roman}
\let\myTOC\tableofcontents
\renewcommand\tableofcontents{
\begin{spacing}{1.1}
\myTOC
\end{spacing}
\clearpage
\pagenumbering{arabic}
}

%% Kopfzeile um Logo ergänzen
\clearscrheadfoot
\ohead{\\\headmark}
\ihead{\includegraphics[scale=0.4]{pics/2015_10_05_THB_Logo_BW}}%\pagemark}
\ofoot[\pagemark]{\pagemark}

%% Randnotizen anpassen
%\setlength{\marginparwidth}{22mm}
%\let \oldmarginpar = \marginpar
%\renewcommand{\marginpar}[1]{%
%    \-\oldmarginpar[\raggedleft\footnotesize\sf #1]%
%        {\raggedright\footnotesize\sf #1%
%    }}

%% Zitate am Kapitelanfang
\usepackage{epigraph}
\setlength{\epigraphwidth}{9cm}

\makeatother

%-----------------------
%  Glossar https://www.sharelatex.com/learn/
%-----------------------
\makeglossaries


\begin{document}
\titlepage

\begin{center}
\includegraphics[width=12cm]{pics/2015_10_05_THB_Logo_CMYK_randlos}\vspace{0.5cm}

\par\end{center}

\vspace{1cm}

\noindent \begin{center}
\textsf{\textbf{\large BACHELORARBEIT}}\textsf{}\\

\textsf{}\\
\textsf{\huge Serverless Architekturen für konventionelle Webanwendungen}
\par\end{center}{\Large \par}

\vspace{2cm}

\noindent \begin{center}
{\huge }\begin{tabular}{rl}
Vorgelegt von: & Dragoljub Milasinovic\tabularnewline
Matrikelnummer: & 20140076\tabularnewline
am: & 23. September 2017\tabularnewline
\end{tabular}
\par\end{center}{\huge \par}

\vspace{1cm}

\noindent \begin{center}
zum \\
Erlangen des akademischen Grades\textsf{}\\
\par\end{center}
\noindent \begin{center}
\textsf{\textbf{\large BACHELOR OF SCIENCE}}\textsf{\textbf{\LARGE }}\\
\textsf{\textbf{(B.Sc.)}}
\par\end{center}

\vspace{1cm}

\noindent \begin{center}
\medskip{}
\begin{tabular}{rl}
Erstbetreuer: & Prof. Dr.-Ing. Schafföner\tabularnewline
Zweitbetreuer: & Jonas Brüstel, M.Sc.\tabularnewline
\end{tabular}
\par\end{center}

\noindent \begin{center}
{\huge }
\par\end{center}{\huge \par}

\newpage{}

\selectlanguage{ngerman}%
\tableofcontents{}

\pagestyle{scrheadings}

\chapter*{Eidesstattliche Erklärung}

Ich versichere hiermit, dass ich die von mir eingereichte Bachelorarbeit selbstständig verfasst, ausschließlich die angegebenen Hilfsmittel benutzt und sowohl wörtliche, als auch sinngemäße entlehnte Stellen als solche kenntlich gemacht habe. Die Arbeit hat in gleicher oder ähnlicher Form noch keiner anderen Prüfungsbehörde vorgelegen.

Brandenburg an der Havel, 21. September 2017

\vspace{3cm}

Dragoljub Milasinovic

\chapter*{Abstrakt}

Die vorliegende Bachelorarbeit untersucht die Flexibilität bei der Gestaltung von Webanwendungen ausschließlich mit Verwendung von Serverless Technologien. Dazu wurde eine Linked Data Driven Webanwendung anhand einer Auswahl von Serverless Entwurfsmuster implementiert. Die Ergebnisse zeigten sowohl Schwierigkeiten bei Sitzungsverwaltung der Nutzern als auch eine große Freiheit bei der architektonischen Komposition von Diensten. Die empirische Bearbeitung erfolgte mit ER-Modellen, Ontologien, Protégé, dem europäischen Kompetenzmodell, SparQL, AWS Lambda, API Gateway, S3 und die Theoretische mit Architekturentwurfsmustern, OpenLambda, DynamoDB, SQS, SES, Kinesis Streams und SNS. Aktuelle Problemlagen im Bereich der Softwarearchitektur, des Projektmanagements, der Wirtschaftsinformatik und der Softwareentwicklung werden aufgegriffen. 

This bachelor thesis was aiming at the analysis of structural flexibility, in the case of a web application that exclusively consists of serverless architectures. An exemplary linked data driven web application was implemented. On the one hand, the results suggested that there are difficulties regarding management of clients' sessions, on the other hand, it provides great freedom of choice within the architectural design of services. The empirical approach dealt with ER-Models, Ontologies, Protégé, the Europe's competency model, SparQL, AWS Lambda, API Gateway, S3 and on a theoretic level with the architectural design patterns, OpenLambda, DynamoDB, SQS, SES, Kinesis Streams and SNS. Current questions of software architecture, project management, economic computer sciences and software development are addressed.


\chapter{Einleitung}
\setcounter{page}{1}
\label{chap:introduction}
%\epigraph{\textit{\textquotedbl{}
%An idea is not a mockup\\
%A mockup is not a prototype\\
%A prototype is not a program\\
%A program is not a product\\
%A product is not a business\\
%nd a business is not profits.\textquotedbl{}}}{
%Balaji S. Srinivasan }

Ideen entstehen, verändern sich, werden im Laufe der Zeit vergessen, manchmal begeistern sie. Ihnen Form und Inhalt zu geben, also sie umzusetzen, ist die Voraussetzung, um nachzuvollziehen ob die ursprüngliche Idee wirklich ausgebaut und verstanden worden ist.

Die Technik kann als Medium für den Ausdruck solcher Ideen eingesetzt werden. Diese kann so komplex werden, dass sie eine Barriere in Form eines Wissensmonopols darstellt, die hinderlich für die Umsetzung neuer Ideen ist.


Die Faktoren am Anfang einer technologischen Umsetzung einer Idee sind:\label{aspect}
der konzeptionelle Beweis, die Vorlaufzeit oder Produkteinführungszeit ( Time-To-Market ), die Personalkosten und Mangel von Fertigkeiten, die technischen und technologischen Details, sowie die Rentabilität.

%\begin{itemize}
%	\item Konzeptioneller Beweis\label{aspect:proofConcept}
%	\item Vorlaufzeit, Produkteinführungszeit ( Time-To-Market ) \label{aspect:timeToMarket}
%	\item Personalkosten und Mangel von Fertigkeiten \label{aspect:costHumanResources}
%	\item Technische und technologische Details\label{aspect:techDetails}
%	\item Rentabilität\label{aspect:profit}
%\end{itemize}


Ein Zeichen für die Existenz dieser Komplexität im Rahmen des Cloudcomputings ist die Entstehung neuer Technologien für die Vereinfachung der Entwicklungsprozesse eines Projekts. 

Je mehr Anforderungen auf ein System z.B. Webanwendung zukommen, desto komplexer wird es. Je mehr Softwarekomponenten, desto mehr Verwaltungsaufwand mittels Load Balancing, Messaging usw. entsteht. Je mehr Dynamik, desto schwieriger ihre Integration und Skalierung.\cite{patternIntegrationEnterprise} 

Mittels des Serveless Architekturstils versuchen die Cloudanbieter diesen Verwaltungsaufwand zu umgehen, die Skalierung zu vereinfachen und Integrationsschwierigkeiten zu lösen.


Um die Umsetzungsvorgänge einer Webanwendung möglichst simpel zu halten, werden in der vorliegenden Arbeit die Serverless Architekturen für konventionelle Webanwendungen untersucht.


\section{Vorgehen}
Auf dem Weg zur technologischen Umsetzung einer neuen Idee treten unbekannte Komplikationen
bei den Entscheidungen über ihre Umsetzung auf. Problematisch können sich der Architekturentwurf, die IT Infrastruktur, die Drittanbieter von Software, die Auswahl der Infrastruktur usw. gestalten. Hinzu kommen Schwierigkeiten, die spezialisierte Kompetenzen, Fertigkeiten und \glqq Know-How\grqq\ erfordern. Diese gehören jedoch nicht immer zum Problem der Domain der Anwendung.

Der Begriff Serverless weist darauf hin, dass die Verwaltung der zugrunde liegenden Serverinfrastruktur der Anwendung von Cloudanbietern übernommen wird. 

\newacronym{FaaS}{FaaS}{Function as a Service}
Für die oben genannten Schwierigkeiten wird \acrfull{FaaS} \autoref{sec:faas}, als Lösung unter der Rubrik \glqq\ Serverless\grqq\ \autoref{sec:serverless} von den Hauptanbietern von \glqq Cloud\grqq\ Technologien vorgestellt.

\acrshort{FaaS} definiert das Programmiermodel, eine Funktion oder auch \glqq Nano-Microservice\grqq genannt, um den serverless Architekturstil zu adaptieren.

\newacronym{AWS}{AWS}{Amazon Web Services}
\newacronym{KOMA}{KOMA}{Kompetenz Matrix}
Im Rahmen des Cloud Computing handelt es sich in dieser Arbeit um eine Untersuchung der Serverless Architekturen am Beispiel einer konventionellen Webanwendung. Dabei wird besonders beachtet, ob und wie solche Technologien die Umsetzung erleichtern. Die Entwurfsmuster und die Kernfunktionalität werden ausschließlich mit Serverless Technologien am Beispiel einer Webanwendung ( \acrfull{KOMA}, siehe \autoref{sec:KOMA} ), mit \acrshort{AWS} umgesetzt.\\
Als Instrument zur Unterstützung von pädagogischer Diagnostik und Intervention werden in \acrshort{KOMA} Kompetenzen und ihre Ausprägungen in Form einer Matrix dargestellt ( d.h. \acrshort{KOMA} ). 


\section{Ziel}
\label{sec:task}
\newacronym{MVP}{MVP}{Minimal Viable Product}
\newacronym{SPA}{SPA}{Single Page Application}
Das Ziel ist ein \acrlong{MVP}, in Form von einer \acrfull{SPA} \autoref{sec:spa}, ausschließlich mit Serverless Technologien zur Verfügung zu stellen.
Die Webanwendung soll möglichst flexibel für zukünftige Änderungen sein.

Anschließend werden die Erfahrungen und Ergebnisse ausgewertet, um zukünftige Entscheidungsprozesse bei der Umsetzung einer Webanwendung zu unterstützen. Es wird hinterfragt, in wie fern der Serverless Ansatz am Beispiel von \acrfull{AWS} die Umsetzung tatsächlich erleichtert. 
Eine weitere Analyse prüft, wie sich eine möglichst hohe Flexibilität bei \acrshort{AWS} erzielen lässt.

\section{Aufbau der Arbeit}
\label{sec:layout}

Die vorliegende Arbeit beschäftigt sich mit dem Serverless Ausschnitt der Cloud Dienste. 

Zuerst wird der Leser in die klassischen Servicemodelle ( \autoref{chap:service-models} ) eingeführt. Zunächst werden die technischen Anforderungen und die dazugehörigen Beispiele des Serverless Ansatzes erläutert.
Das nächste Kapitel überblickt die aktuellen Serverless Angebote der größten Cloud Anbieter.
Den Kern der Arbeit bildet die Analyse und Darstellung von Serverless Architekturen ( \autoref{chap:aws-serverless} ) und sie fokussiert sich auf \acrshort{AWS}. In diesem Abschnitt werden die Serverless Architekturen ( \autoref{chap:aws-serverless} ) und das Programmiermodell vorgestellt, sowie die Entscheidungsprinzipien ( \autoref{par:serverless-principles} ) erläutert.
Der praktische Teil setzt sich aus der Umsetzung und Bewertung von der oben genannten Serverless Webanwendung KOMA ( \autoref{sec:KOMA} ) zusammen.

Am Ende erfolgt eine Diskussion darüber, welche Trade-offs entstehen und welche Zukunftsperspektiven Serveless Technologien bieten.


\chapter{Klassische Service-Modelle}
\label{chap:service-models}
\label{chap:principles}
%\epigraph{\textit{\textquotedbl{}
%There are only two hard things in computer science:\\ cache invalidation and naming %things.\textquotedbl{}}}{ Phil Karlton }

Um wiederkehrende IT-Probleme zu beheben, werden Service-Modelle entworfen. Als solches beschreibt
Cloud Computing die Bereitstellung von IT-Infrastruktur und IT-Leistungen wie beispielsweise Speicherplatz, Rechenleistung oder Anwendungssoftware als Service über das Internet.\cite{cloudEssentials}

%\section{Cloud Eigenschaften}
\label{sec:cloud-char}
Aus einem Meer von Cloud Diensten ist die richtige Auswahl je nach Anforderungen und Art der technologischen Umsetzung schwer zu treffen. Als Softwarearchitekt, Entwickler oder Projektmanager ist es daher wichtig, die spezifischen Eigenschaften von Cloud Angeboten zu verstehen. 


Im Allgemeinen teilen Cloud Angebote laut Chandrasekaran ( \cite{cloudEssentials} ) folgende Merkmale:
\begin{itemize}
	\item On-Demand Self-Service - Nutzer können die IT-Kapazitäten, die sie benötigen, selbständig ordern und einrichten. Der Anbieter muss in den Prozess nicht eingebunden werden.
	\item Broad Network Access bezeichnet den standardbasierten Netzzugriff von verschiedenen Endgeräten ( z.B. Smartphones, Tablets, Laptops, PCs ) aus.
	\item Measured Service bietet eine automatische Kontrolle und Optimierung der genutzten Ressourcen durch ihre Dosierung ( Metering ), wodurch Transparenz für Anbieter und Nutzer sichergestellt wird. Somit bezahlen Kunden nur die Dienstleistungen, die sie auch tatsächlich in Anspruch nehmen.
	\item Resource Pooling ( \ref{par:polling} ) - Ressourcen des Anbieters (z.B. Speicher oder Bandbreite) werden gebündelt, multimandantenfähig bereitgestellt und nach Bedarf zugewiesen.
	\item Rapid Elasticity ( \autoref{app-char:elascitity} ) - Kapazitäten sind schnell und dynamisch verfügbar und können je nach Bedarf skaliert werden.
\end{itemize}

Daher ergeben sich für die, in der Cloud betriebenen Anwendungen, folgende Eigenschaften \cite{cloudEssentials}: 
\begin{itemize}
	\item Isolated state - Der Zustand wird in kleinen Einheiten der Anwendung isoliert, so dass sie besser skalieren. Eine zustandslose IT Ressource kann ohne Synchronisierungen aggregiert oder gelöscht werden. Dieser Zustand bezieht sich nicht nur auf die Verwaltung der Interaktionen eines Clients, sondern auch auf dessen Datenverarbeitung. 
	\item Distribution - Anwendungen müssen so in Komponenten zerlegt werden, dass sich ihre Ressourcen weltweit auf-/verteilen.
	\item Elasticity\label{app-char:elascitity} - Die Anpassung sowohl auf die Anzahl als auch auf die Leistungsfähigkeit der zu benutzenden IT Ressourcen kann im Sinne einer Addition oder Subtraktion erfolgen. Im ersten Fall nimmt auf der Ebene der horizontalen Skalierung ( scale out ) die Anzahl der Server zu. Während bei der vertikalen Skalierung ( scale up ) die Leistungsfähigkeit der Ressourcen der Server steigt.
	\item Automated management - Die konstanten Aufgaben zur Verwaltung von Elasticity sollen automatisiert werden, um eine Cloudanwendung fehlerresitent auf Ressourcenebene zu implementieren.
	\item Loose coupling - Die Minimierung von Abhängigkeiten einer Anwendung von IT Ressourcen vereinfacht die Bereitstellung, die Fehlerkontrolle und Wiederverwendung von Komponenten. \autoref{sec:soa} 
\end{itemize}

Die nächsten Unterkapitel stellen exemplarisch klassische Service-Modelle vor.

\section{IaaS}
\label{sec:iaas}
\newacronym{IaaS}{IaaS}{Infrastructure as a Service}
\acrfull{IaaS} kann als ein Service beschrieben werden, der Abstraktionen für Hardware, Server und Netzwerkkomponenten bereitstellt. Der Serviceanbieter stellt die Ausrüstung zur Verfügung und ist für die Unterbringung, die Inbetriebnahme und die Wartung der Server verantwortlich\cite{patternAWS}. Der Benutzer bezahlt nicht für die Hardware, deren Lagerung und den Zugriff, sondern für die Nutzung des gesamten Servicemodells z.B.: Zahlung nach benutzten Stunden, Ressourcen usw.

Die Aufgaben\label{sec:iaas-aufgaben} für Systeme mit Softwareelementen wie Load Balancing, Transaktionen, Gruppierung ( Clustering ), Caching, Benachrichtigung ( Messaging ) und Datenredundanz werden komplexer. Diese Elemente fordern an, dass Server zu verwalten, warten, flicken ( patched ) und zu sichern sind. In einer nicht-trivialen Systemumgebung sind solche Aufgaben zeitintensiv, aufwändig fertigzustellen und daher schwer effizient zu betreiben. Infrastruktur und Hardware sind zwar nötige Komponenten für jegliche IT-Systeme, aber gleichzeitig stellen sie nur das Medium für deren Anwendung dar - sei es Geschäftslogik, oder ein darauf aufbauender Dienst.\cite{cloudEssentials}

\section{PaaS}
\label{sec:paas}
\newacronym{PaaS}{PaaS}{Platform as a Service}
\acrfull{PaaS}, kann als ein Service beschrieben werden, der eine Rechenplattform liefert, z.B. ein Betriebssystem, eine Ausführungsumgebung für Programmiersprachen (siehe ElasticBeanstalk \cite{ebs}), eine Datenbank oder einen Webserver. Dieser Dienst übernimmt je nach benutzerdefinierter Konfiguration sowohl die Wartung der Datenbank, des Webservers und der Versionen des Laufzeitquellcodes, als auch deren Skalierbarkeit.\cite{patternAWS}.


\textit{Inkonsistenzen} in der Infrastruktur oder den Umgebungen können durch den hohen Aufwand der Serververwaltung entstehen. Sie werden durch standardisierte und automatisierte Angebote von \acrshort{PaaS} umgangen. Deren effiziente Benutzung ist abhängig davon, wie gezielt der Quellcode auf die Features der Plattform abgestimmt ist. Dies ergibt auf einer Seite weniger Wartung, aber andererseits erfordern die importierten Anwendungen ( z.B. für ein \glqq Standalone\grqq\ Server ) eine Anpassung an die Plattform.

Die \textit{Containerisierung}\label{par:containerisation} ist eine Isolierung der Anwendung von ihrer Umgebung. Die Konfiguration des Containers, sowie dessen Einsatz ( Deployment ) ist nicht trivial und erfordert daher spezialisiertes Wissen über Containerisierung. Für das Monitoring werden bestimmte Tools wie Boot2Docker \cite{Boot2Docker} oder cAdvisor \cite{cAdvisor} benötigt. Jedoch bietet die Containerisierung eine ausgezeichnete Lösung für Anwendungen mit starker Kopplung zu anderen Softwarekomponenten.\cite{patternAWS}

%Der Container muss konfiguriert und gebaut werden und der Deploymentprozess ist nicht trivial. 

%\begin{wrapfigure}{i}{0.66\textwidth}
%	\includegraphics[scale=0.36]{./pics/IaaS_vs_PaaS_vs_Serverless.eps}
%\end{wrapfigure}
\section{SaaS} 
\label{sec:saas}
\newacronym{SaaS}{SaaS}{Software as a Service}
\acrfull{SaaS} kann als ein Service beschrieben werden, der OS-Images mit konfigurierbaren Diensten wie Datenbanken, Webanwendungen usw. bereitstellt. \acrshort{SaaS} gestaltet sich benutzerfreundlich, da die Konfiguration und das Deployment dieser Softwaredienste nicht erlernt werden müssen, um sie in eine größere Anwendung einzubinden. Anfallende Gebühren berechnen sich nach der Nutzungsdauer.\\
Ein Großteil traditioneller Software bietet seine Version als \acrshort{SaaS} nicht an. Dies impliziert laut Chandrasekaran, dass dieses Serviceliefermodell sich für Anwendungen nicht gut eignet wegen der folgenden Punkte:
\newacronym{SLA}{SLA}{Service Level Agreement}
\begin{itemize}
	\item Geringe Latenz kann durch die Entfernung der gespeicherten Daten für Echtzeitanwendungen nicht gewährleistet werden.
	\item Die Datensicherheit kann nicht sichergestellt werden, da die mitbeteiligten Drittanbieter bei \acrshort{SaaS} die \acrfull{SLA}s von Kunden nicht immer erfüllen.
	\item Anforderungen bestimmter Software verlangen eine Zentralisierung und eine Lokalisierung vor Ort, anders als bei \acrshort{SaaS}. 
\end{itemize}\cite{cloudEssentials}

\newglossaryentry{virtualization}{name={Virtualisation},description={Abstraktion der Anwendung, OS oder DB von der darunterliegende Infrastruktur z.B. ein Server.}}

%Diese Softwaredienste lassen sich zwar aggregieren, aber die Skalierung des daraus resultierende Softwarestacks erfolgt durch Notifikation des Drittanbieters, wodurch  

%Das \glqq\Gls{virtualization}\grqq\ einer ganzen Umgebung oder Stack zerteilt sich in eine Sammlung von kleinen spezialisierten Aufgaben, die durch Drittanbieter implementiert wurden. Dieser Fakt steigerte die wirtschaftlichen Kosten und machte die Skalierungsmöglichkeiten komplexer\cite{patternAWS}.


\chapter{FaaS als Grundlage der Serverless Architekturen}%{nichtfunktionalen/technischen Anforderungen zur Entwicklung des Serverless-Ansatzes}

\acrfull{FaaS}\label{sec:faas} kann als ein Rechenservice beschrieben werden, der nach Anfrage isoliert, unabhängig und granular ausgeführt wird. Komplexe Probleme wie horizontale und vertikale Skalierbarkeit, Fehlertoleranz und Elastizität werden von Kunden nur noch nach Bedarf konfiguriert und von dem Anbieter verwaltet. Die Besonderheit von \acrshort{FaaS} ist die \glqq Unit of Deployment\grqq\ und die Skalierung in Form einer Funktion. \cite{patternAWS}


%e (FaaS) is somewhat smaller as Software-asa-Service
Somit lässt sich in der folgenden \autoref{comparison-xaaS} die Skalierungseinheit ( Unit of Deployment ) und die Abstraktionsebene von den relevanten Dienstmodellen vergleichen. 
\begin{table}[H]
	\caption{Vergleich IaaS PaaS FaaS Skalierung und Abstraktion}	
	\centering{}
	\begin{tabular}{ c | c c c }
		\noalign{\vskip\doublerulesep}
		& IaaS & PaaS & FaaS 
		\tabularnewline[\doublerulesep]	\hline	
		\noalign{\vskip\doublerulesep}
		Skalierungseinheit & Virtuelle Maschine & Anwendung & Funktion \tabularnewline
		Abstraktion & Hardware & Betriebssystem & Laufzeitumgebung der Sprache
	\end{tabular}
\label{comparison-xaaS}
\end{table}

% ---- revise 
Im Rahmen des \glqq Open Lambda\grqq\ Projekts wurde die Latenz zwischen einer \acrshort{PaaS} und einer \acrshort{FaaS} Anwendung verglichen. Deren Autoren ( siehe \cite{lambdaOpen} ) stellten fest, dass die Funktion kürzere Antwortzeiten lieferte, weil sie für jede Anfrage eine neue Instanz kreierte, wogegen die \acrshort{PaaS} nicht skalierte u.d. die Anfragen in eine Queue ( Schlange ) einreihte. 

Es werden nun die konzeptionellen Bestandteile von \acrshort{FaaS} näher ausgeführt.

\textit{Events}\label{par:event-reaction} innerhalb eines verteilten Systems müssen verwaltet werden. Technologien wie virtualisierte oder containerized Server erzeugen neue Serverinstanzen zur Verarbeitung von einer Kette von variablen Events, die danach gelöscht werden.\cite{lambdaAWS} Die entstehende Problematik ergab sich durch eine starke Zunahme an Elementen, die einen hohen Verwaltungsaufwand forderten.  Was zurück auf die oben genannten Aufgaben \autoref{sec:iaas-aufgaben} führte.

\textit{Polling}\label{par:polling} ist der Ausdruck für eine zyklische Abfrage über einen Status den Ressource z.B. von Ports oder Locks. Die Verwendung von Systemressourcen ist ineffizient im Vergleich zu Alternativansätzen wie z.B in dem Push- oder Pull- Kommunikationsmodell.\cite{lambdaAWS} 

\textit{Funktionale Programmierung} ist ein Programmierparadigma, in dem Funktionen nicht nur definiert und angewendet werden können, sondern auch wie Daten miteinander verknüpft, als Parameter verwendet und als Funktionsergebnisse auftreten können. Zustand und mutable Daten werden vermieden, damit Nebeneffekte nicht entstehen und die Komposition flexibler wird. Das stellt einen Vorteil für die Skalierung eines Softwarekomponenten dar.\cite{funcScala}


Die Implementierung einer solchen Funktion geschieht durch die Auswahl der Programmiersprache und der von dem Cloudanbieter vorgegebenen Funktionsfassade. Diese wird vom Cloudanbieter aufgerufen, stellt aber keine zusätzlichen Bibliotheken zur Verfügung, daher ist es nötig, dass die auszuführende Datei alle Abhängigkeiten enthält.


Der Fokus bei \acrshort{FaaS} liegt auf der Quellcodeentwicklung und nicht auf der Bereitstellung ( Provisioning ) von Servern, der Installation von Software, dem Einsatz ( Deployment ) von Containern oder auf konkreten Details der Infrastruktur.


Für die Betrachtung, ob \acrshort{FaaS} eine Lösung für eine konkrete Problemstellung ist, folgt eine Auflistung von Kriterien nach King\cite{lambdaAWS}:\\
Es ist nicht empfehlenswert \acrshort{FaaS} zu benutzen, wenn: \label{lambda-yes-no}
\begin{itemize}
	\item der Entwickler Rootzugriffsrechte auf alle Ressourcen eines Servers benötigt
	\item die Priorisierung von Betriebssystemattributen wie CPU, GPU, Networking oder Speichergeschwindigkeit angefordert ist
	\item Sicherheit relevant ist. Unautorisierte Zugriffe können mit \acrshort{FaaS} nur auf Systemebene erkannt werden
	\item dauerhaft laufende Prozesse angefordert sind
\end{itemize}


Es ist empfehlenswert \acrshort{FaaS} zu benutzen, wenn:
\begin{itemize}
	\item Aufgaben als Reaktion auf Events erledigt werden
	\item ein Scriptbehälter für z.B Cron-Aufgaben benötigt wird. Hier sind die Zugriffsrechte beschränkter, Fehler einfacher zu erkennen und an einer Stelle aggregiert ( \cite{awsCloudWatch} ), des Weiteren können Deployments einfacher angestoßen werden
	\item die Skalierung des Servers bei einer ressourcenintensiven Verarbeitung vermieden werden soll \autoref{sec:pipes-filters}
	\item Services vorgegeben sind, die selten benutzt werden
	\item die Verwaltung von \acrshort{API}-Server umgangen werden soll
\end{itemize}


Die Frage, wie sich Architekturen mit einer \acrshort{FaaS} Technologie gestalten, wird im nächsten Kapitel erläutert.

\chapter{Serverless-Angebote und Architekturen}

Durch Softwarearchitekturen wird kommuniziert, für welchen Zweck die Software konzipiert ist. Ihre Entwurfsmuster bieten generische Lösungen für wiederkehrende Probleme bei der Softwareentwicklung.


Eine konventionelle Webanwendung in diesem Sinne, ist ein System, das über eine Präsentation-, Daten- und Logikschicht verfügt. Jede Schicht kann mehrere Logik-Layers enthalten, die für unterschiedliche Funktionalitäten der Domains verantwortlich sind. Logging ist ein Beispiel für das Cross-Cutting Concern, das Layers überspannt. Die Komplexität der Anwendung wächst zusammen mit der Anzahl der Schichten.
Eine Überprüfung der Architektur ist sinnvoll, wenn eine erfolgreiche Codeänderung von einer Anderen abhängt.

\newacronym{SOA}{SOA}{Service Oriented Architecture}
\acrfull{SOA}
\label{sec:soa} unterliegt der Annahme, dass ein System aus mehreren kleinen, austauschbaren, wiederverwendbaren und entkoppelten Diensten besteht. Für die Entwicklung und Integration solcher Systeme liefert \acrshort{SOA} eine Reihe von Entwurfsprinzipien und Standards. Entwickler erstellen autonome Services, die durch Nachrichtenübergabe kommunizieren und oft ein Schema haben oder eine Schnittstelle, die definiert, wie die Nachrichten erzeugt werden.\cite{cloudEssentials}

\begin{figure}[H]
	\centering	
	\includegraphics[scale=0.80]{./pics/arch-soa.eps}
	\caption{SOA Architekturreferenz\cite{archSoa}}
	\label{pic:arch-soa}
\end{figure}


SOA ermöglicht gegenseitigen Datenaustausch zwischen Programmen von unterschiedlichen Anbietern, ohne dass zusätzliche Änderungen an den Services vorzunehmen sind. Die Bestandteile eines solchen Architekturstils sind sowohl Standardschnittstellen als auch voneinander unabhängige Services\cite{archSoa}. 

Der Fokus in der Cloud liegt daher auf Service und Servicekomposition \cite{cloudEssentials}.

\newacronym{DSL}{DSL}{Domain Specific Language}
Microservices und Serverless versuchen die Komplexität der SOA ( \autoref{pic:arch-soa} ) anzusprechen. Beide Ansätze führen  Separation of Concerns, häufige Deployments und heterogene \acrfull{DSL}s mit sich.\cite{microAdv}

Auf einer Seite können Microservices ihren Zustand sowie ihre Daten speichern und mit Hilfe von Frameworks implementiert werden. Auf der anderen Seite sind Serverless Architekturen zustandlos, ihre Datenspeicherung ist zeitlich begrenzt und sie unterstützen Frameworks nicht direkt. ConnectWise\cite{ConnectWise}, Netflix\cite{Netflix} und UNLESS\cite{UNLESS} sind Beispiele für Unternehmen, die auch von Serverless Architekturen profitieren.


\newacronym{EDA}{EDA}{Event Driven Architecture}
\textit{\acrfull{EDA}}\label{sec:eda} ist eine Softwarearchitektur, in der das Zusammenspiel der Komponenten durch Ereignisse gesteuert wird. Die Ereignisorientierung besitzt das Potenzial, dass die Architekturen von Anwendungen agiler, reaktionsschneller und
echtzeitfähig werden. Laut Ralf Bruns und Jürgen Dunkel zeichnet sich \acrshort{EDA} durch komplexe Fachlogik, große Datenvolumina, geringe Latenzzeit, Skalierbarkeit und Agilität aus.\cite{archEDA}\\
Die Serverless Technologien können durch Benachrichtigungen gestartet werden. Dieser \acrshort{EDA}-Stil verstärkt die Entkopplung auf einer temporären Ebene zwischen Producer und Consumer. Weiterhin ermöglicht ein Kommunikationskanal zur Benachrichtigung eine asynchrone Verarbeitung, ohne dass das System auf Grund von Fehlern abstürzt. \cite{patternIntegrationEnterprise}

Zusammenfassend sind folgende Vorteile ersichtlich \cite{cloudEssentials}:
\begin{itemize}
	\item Die Wiederverwendung von Services in unterschiedlichen Anwendungen senkt die Entwicklungskosten und den Time-To-Market.
	\item Durch die Standarisierung der Services kann ein System mit einer Rekonfiguration und ohne Weiterentwicklung schnell auf die geschäftlichen oder externen Bedürfnisse angepasst werden. Somit wird ein agiles Arbeiten möglich.
	\item Das Monitoring hilft Fehler zu erkennen und die Leistung zu messen.
	\item Aggregate von bereitgestellten Services können komplexere und domainübergreifende Aufgaben ausführen.
\end{itemize}

\newacronym{REST}{REST}{REpresentational State Transfer}
Im späteren Kapitel wird REST als Teil des \acrshort{EDA}-Architekturstils vorgestellt.\\

\section{Serverless}
\label{sec:serverless}

\newacronym{API}{API}{Application Interface}
Serverless kann als ein Ansatz beschrieben werden, der die Verwendung von einem Rechenservice, Dienste von Drittanbietern, von \acrfull{API}s und die Anwendung von Architekturmustern fördert. Ein solcher Anwendungsfall ist die Kommunikation mithilfe eines \glqq Delegation-Tokens\grqq\ zwischen den Front- und Back-End Diensten. \acrshort{FaaS} ist nur ein Aspekt dessen.


Serverless übernimmt die Entwurfsprinzipien von \acrshort{SOA} und \acrshort{EDA} ( siehe \autoref{sec:soa} ) und daher ergeben sich laut Sbarski folgende Richtlinien:
\newacronym{SRP}{SRP}{Single Responsability Principle}
\begin{itemize}\label{par:serverless-principles}
	\item Ein Rechenservice wird genutzt, um Quellcode auf Anfrage auszuführen, kein Server.
	\item Zustandslose Funktionen unterliegen dem \acrfull{SRP}.
	\item Für den Architekturentwurf werden Push basierte ereignisorientierte Pipelines genutzt.
	\item Front-Ends werden durch die Einbettung von mehr Zuständigkeiten verstärkt.
	\item Dienste von Drittanbieter werden dem Schreiben von eigenem Quellcode bevorzugt.
\end{itemize}\cite{serverlessArchAWS}

Die Vernetzung von zustandslosen Funktionen erlaubt, komplexe Systeme zu entwerfen, die einfach zu skalieren sind.
\newacronym{MVC}{MVC}{Model View Controller}
Die Komplexität und längerfristige Wartbarkeit des Systems lässt sich dadurch reduzieren, dass der Controller und/oder Router aus dem \acrfull{MVC} \cite{fowlerBlogMVC} vom Back- zum Front-End verschoben wird und Dienste von Drittanbieter hinzugefügt werden. \cite{patternAWS}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.60]{./pics/classic-example.eps}
	\caption{Classic Add Server}
	\label{pic:classic-add}
\end{figure}
In einem beispielhaften konventionellen AdServer wird nach einem Klick auf eine Werbung eine Nachricht über einen Kanal an einen Klickprozessor geschickt, der innerhalb einer Anwendung ausgeführt wird.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.60]{./pics/serverless-example.eps}
	\caption{Serverless Add Server}
	\label{pic:serverless-add}
\end{figure}
%\begin{wrapfigure}{l}{0.36\textwidth}
%	\includegraphics[scale=0.30]{./pics/serverless-example.eps}
%	\caption{Serverless Add Server}
%	\label{pic:serverless-add}
%\end{wrapfigure}

Mit dem Serverless Ansatz wird dieser Klickprozessor pro Nachricht als eine neue Instanz der Funktion ausgeführt. Ihre Laufzeitumgebung und ihr Messagebroker wird von dem Cloudanbieter verwaltet. \cite{fowlerBlogServerless}
 
Dazu wird für den Entwurf von Serverless Architekturen eine Reihe von Mustern von unterschiedlichen Autoren vorgeschlagen.


\section{Pipes and Filters, Compute as a Glue}
\label{sec:pipes-filters}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.60]{./pics/pipes-and-filters.eps}
	\caption{Pipes and Filters Entwurfsmuster}
	\label{pic:pipes-and-filters}
\end{figure}
%\begin{wrapfigure}{l}{0.36\textwidth}
%	\includegraphics[width=0.9\linewidth]{./pics/pipes-and-filters.eps}
%\end{wrapfigure}
Eine Anwendung kann Aufgaben von unterschiedlicher Komplexität bewältigen. In einem monolithischen Modul sind das Refactoring, die Optimierung und die Wiederverwendung erschwert. \\
Zunächst werden die Aufgaben in diskrete Elemente ( oder Filter ) nach dem \acrshort{SRP} zerteilt und in einer Pipeline kombiniert. Dies hilft redundanten Quellcode zu vermeiden, ihn zu löschen, zu ersetzen oder in zusätzliche Komponenten zu integrieren, sobald sich die Aufgabenanforderungen ändern\cite{patternsCloud}. Ein weiterer Vorteil besteht darin, dass ein Flaschenhalseffekt vermieden wird, in dem mehrere Instanzen erzeugt werden, falls ein Element nicht genug Ressourcen für die Verarbeitung hat. 


\section{Legacy Api Proxy}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.60]{./pics/legacy-api-proxy.eps}
	\caption{Legacy API Muster}
	\label{legacy-api-proxy}
\end{figure}
%\begin{wrapfigure}{l}{0.36\textwidth}
%	\begin{center}
%		\includegraphics[width=0.9\linewidth]{./pics/legacy-api-proxy.eps}
%		\label{legacy-api-proxy}
%		\caption{Legacy API Muster}
%	\end{center}
	
%\end{wrapfigure}
Wenn eine \acrshort{API} veraltet oder schwer zu benutzen ist, kann eine extra ( RESTful ) \acrshort{API} in den Vordergrund gestellt werden, die in gesonderten Prozessen Daten transponieren und für die angeforderten Formate aufstellen ( marshall ). Dies ist besonders nützlich, wenn die Legacy-Services selten benutzt werden. Zusätzlich erleichtert der Api Proxy die Integration mit anderen Architekturansätzen.


\section{Compute as a Backend}
\begin{figure}[H]
	\centering
		\includegraphics[scale=0.60]{./pics/compute-as-a-backend.eps}
	\caption{Compute as a Backend Muster}
	\label{pic:compute-backend}
\end{figure}
%\begin{wrapfigure}{l}{0.46\textwidth}
%	\includegraphics[scale=0.36]{./pics/compute-as-a-backend.eps}
%	\caption{Compute as a Backend}
%	\label{pic:compute-backend}
%\end{wrapfigure}
Obwohl der Client direkt mit Services kommunizieren kann, müssen vertrauliche Informationen geschützt werden, indem sie das Back-End verarbeitet\cite{serverlessArchAWS}. Diese Aufgaben können hinter einer \acrshort{REST} Schnittstelle koordiniert werden. Wie in  \autoref{par:serverless-principles} erwähnt, minimieren die Einbettung der Dienste von Drittanbietern und verstärkte Front-Ends den Fußabdruck des eigenen Back-Ends.

\section{Graph Query}
\begin{figure}[H]
	\centering
		\includegraphics[scale=0.60]{./pics/GraphQuery.eps}
	\caption{Graph Query Muster}
	\label{pic:graph-query}
\end{figure}
%\begin{wrapfigure}{l}{0.36\textwidth}
%	\includegraphics[scale=0.36]{./pics/GraphQuery.eps}
%	\caption{Graph Query}
%	\label{pic:graph-query}
%\end{wrapfigure}
Wenn mit einer Anfrage mehrere Datenbanken abgefragt werden, entstehen multiple Paketumlaufzeiten ( Round-Trip ). Stellt eine \acrshort{REST} Schnittstelle in einer Anfrage zu wenig Queryparameter zur Verfügung, dann entsteht Overfetching, weil die Anfrage nicht präzise genug ist. Dagegen kann der Client die Parameter für die Abfrage spezifizieren und das Back-End baut sie zusammen und führt sie aus.


\section{Real time processing}
\begin{figure}[H]
	\centering
		\includegraphics[scale=0.60]{./pics/real-time-processing.eps}
	\caption{Real Time Processing Muster}
	\label{pic:real-time-processing}
\end{figure}
%\begin{wrapfigure}{l}{0.36\textwidth}
%	\includegraphics[scale=0.36]{./pics/real-time-processing.eps}
%	\caption{Real Time Processing}
%	\label{pic:real-time-processing}
%\end{wrapfigure}
Die Verarbeitung von Streams in Echtzeit kann durch einen Puffer erfolgen, der je nach Konfiguration die Daten weiter an den Worker leitet. Einen wesentlichen Vorteil stellt die unabhängige Skalierung des Streams und des Workers je nach Anfrage dar. Bei fehlerhafter Verarbeitung werden die Prozesse neu angestoßen.

\section{Priority Queue}\label{sec:priority-queue}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.60]{./pics/pattern-priority-queue.eps}
	\caption{Priority Queue Muster}
	\label{pic:priority-queue}
\end{figure}
%\begin{wrapfigure}{l}{0.36\textwidth}
%	\includegraphics[scale=0.36]{./pics/pattern-priority-queue.eps}
%	\caption{Priority Queue}
%	\label{pic:priority-queue}
%\end{wrapfigure}
Anwendungen können spezifische Aufgaben delegieren, wie z.B die Integration mit anderen Anwendungen und Services. Anders als bei einer FIFO  ( First In First Out ) Queue können die Nachrichten nach Priorität automatisch sortiert und asynchron verarbeitet werden. Für Systeme ohne integrierte Priorisierung können mehrere Queues für unterschiedliche Prioritäten benutzt werden und die Anzahl von Consumerprozessen wird entsprechend angepasst. Im letzteren Fall wird dabei die Starvation von Nachrichten, mit geringer Priorität, vermieden.

Das Priority Queue wird im Rahmen des Entwurfsmusters Competing Consumers als ein Consumerservice aufgefasst. Steigt stark die Anzahl von Anfragen an die Kapazitäten des Systems, kommt es zu seiner Überbelastung. Ein Consumerservice als Moderator von Anfragen ist im Stande das zu verhindern.

\section{Fan Out}
\label{sec:fan-out}
\begin{figure}[H]
	\centering
\includegraphics[scale=0.60]{./pics/pattern-fan-out.eps}
\caption{Fan Out}
\label{pic:fan-out}
\end{figure}
%\begin{wrapfigure}{l}{0.45\textwidth}
%	\includegraphics[height=3cm]{./pics/pattern-fan-out.eps}
%	\caption{Fan Out}
%	\label{pic:fan-out}
%\end{wrapfigure}
Bei dem Eintritt eines Events können ein oder mehrere Subscriber durch die gepushte Benachrichtigung angestoßen werden. Damit wird ein Kommunikationskanal  \autoref{sec:priority-queue} zur Verwaltung von Nachrichten wiederverwendet und extra Geschäftslogik umgangen, z.B. kein Command Pattern für die gleiche Funktionalität\cite{serverlessArchAWS}.

\section{Federated Identity}\label{sec:federated-identity}
\begin{figure}[H]
	\centering
\includegraphics[scale=0.60]{./pics/pattern-federated-identity.eps}
\caption{Federated Identity}
\label{pic:federated-identity}
\end{figure}
%\begin{wrapfigure}{l}{0.36\textwidth}
%	\includegraphics[scale=0.36]{./pics/pattern-federated-identity.eps}
%	\caption{Federated Identity}
%	\label{pic:federated-identity}
%\end{wrapfigure}
Benutzer arbeiten mit multiplen Anwendungen von unterschiedlichen Organisationen. Um gleiche Zugangsdaten für Benutzter wiederverwenden zu können, wird dem Nutzer eine Identität bei einem Drittanbieter zugeteilt, diese wird mit einem Token an die Anwendung weitergeleitet. Der Authentisierungscode kann daher von dem Anwendungscode abgetrennt werden, damit kann zusätzliche Komplexität bei der Codierung für die Authentisierung vermieden werden.

\chapter{AWS-Serverless-Angebote}
\label{chap:aws-serverless}
\acrshort{AWS} ist ein Cloudandbieter unter vielen.
Hier ein Überblick über verschiedene \acrshort{FaaS} Angebote:\\

\begin{table}[H]
	\centering{}
	\label{comparison-FaaS}
	\begin{tabular}{ p{7em} | p{2cm} | p{2cm} | p{2cm} | p{2cm} | p{2cm} }
		& AWS Lambda & Iron.io & Google Funktions & MS Funktions & IBM OpenWhisk  \\
		\hline
		JS & + &  & + & + & + \\
		\hline
		Python & + & + &  & + & + \\
		\hline
		Java & + & + &  &  & + \\
		\hline
		Trigger &  &  &  &  &  \\
		\hline
		- Event Trigger  & + &  & + &  & + \\
		\hline
		- HTTP Trigger & + &  & + &  &  \\
	\end{tabular}
\\
\caption{Vergleich \acrshort{FaaS} Angebote der Cloudanbietern}
\end{table}

\acrshort{AWS} zeichnet sich dadurch aus, dass \acrshort{FaaS} gut in seinem Ökosystem integriert ist. Da \acrshort{KOMA} mit \acrshort{AWS} umgesetzt ist, folgt eine Beschreibung der unterschiedlichen \acrshort{FaaS} Angebote.


\newacronym{JVM}{JVM}{Java Virtual Machine}
\begin{wrapfigure}{l}{0.16\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/Compute_GRAYSCALE_AWSLambda.eps}
\end{wrapfigure}
\paragraph{Lambda}\label{par:lambda} ist ein Rechenservice, der aus Quellcode und dessen Abhängigkeiten besteht. Die horizontale Skalierung erfolgt automatisch, elastisch und vom Cloudanbieter verwaltet; währenddessen die vertikale nach Konfiguration erfolgt. Lambda wird als Einheit für die Skalierung und das Deployment benutzt. \acrshort{AWS} unterstützt Javascript, Python, C\# und Java. Die letzte Programmiersprache betrifft das Konzept \glqq Cold- und Warm\label{lambda-cold-warm} run\grqq\ besonders, da es nötig ist, die \acrfull{JVM} in ihrer Laufzeitumgebung hochzufahren ( cold run ). Der Cloudanbieter stützt sich auf das Pull- und Push- Kommunikationsmodell. Bei Pull überprüft die Lambda Laufzeitumgebung in regelmäßigen zeitlichen Abständen, ob Events z.B. bei Kinesis eingetreten sind und ruft die entsprechende Lambda Funktion mit einer Event-Datennutzlast auf. Bei Push ruft die Eventquelle z.B S3 je nach Konfiguration ( event source mapping ) die entprechende Lambda Funktion auf. 

Zustände können von anderen Dienste wie einer Datenbank aufgerufen werden.


% --- revise 
\newacronym{RPC}{RPC}{Remote Procedure Call}
In der folgenden \autoref{lambda-arch} findet sich eine Übersicht der Architektur von Lambda. Nachdem der Load Balancer ein Event ( 1 ) in Form eines \acrfull{RPC}s aufgenommen hat, wird der Server benachrichtigt ( 2 ) und lädt ( 3 ) entsprechenden Quellcode in die Arbeitsspeicher ( 4 ), um ihn auszuführen und die Ergebnisse zurück an den ursprünglichen Load Balancer zu senden( 5 ). 

\begin{figure}[H]
	\centering{}
	\includegraphics[scale=0.60]{./pics/lambda-arch.eps}
	\caption{Vereinfachte Architektur von Lambda}
	\label{lambda-arch}
\end{figure}

Der Ausgangspunkt dieses Entwurfs legt die gemeinschaftliche Benutzung von vorhandenen Ressourcen, so oft es sich anbietet, nahe.

Steigt die Anzahl der \glqq Worker\grqq\ , entsteht die horizontale Skalierung. Diese kann bis Null sinken, u.d. kann der Benutzer sich die Kosten für nicht benutzte Ressourcen sparen.  


\begin{wrapfigure}{l}{0.16\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/MobileServices_GRAYSCALE_AmazonAPIGateway.eps}
\end{wrapfigure}
\paragraph{API Gateway} ist eine Fassade, um Operationen sicher auszuführen, wie die Benachrichtigung von Kunden per Email und deren Identitätsüberprüfung. Weil AWS die Skalabilität von API Gateway und von Lambda übernimmt, ist die Bereitstellung und Wartung von EC2 Instanzen und die Konfiguration deren Load Balancer nicht mehr nötig. 

\begin{wrapfigure}{l}{0.16\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/Messaging_GRAYSCALE_AmazonSNS.eps}
\end{wrapfigure}
\newacronym{SNS}{SNS}{Simple Notification Service}
\paragraph{\acrfull{SNS}}\label{par:sns} erweitert das schon gut etablierte Beobachtermuster, in dem es einen Kanal für Events hinzufügt. Die konzeptionelle Technologie hinter \acrshort{SNS} wird als \glqq Publish-Subscribe Channel\cite{patternIntegrationEnterprise}\grqq\ Muster bezeichnet und entspricht den oben genannten \glqq Fan Out\grqq\ \autoref{sec:fan-out} Architekturmustern. AWS kann durch Redundanz mindestens eine Lieferung der Nachricht gewährleisten.


\newacronym{S3}{S3}{Simple Storage Service}
\newacronym{SQS}{SQS}{Simple Queue Service}
\begin{wrapfigure}{l}{0.16\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/Storage_GRAYSCALE_AmazonS3.eps}
\end{wrapfigure}
\paragraph{\acrfull{S3}} ist ein Speicherdienst, der durch \acrshort{SNS} \autoref{par:sns} die Events ( z.B das Löschen oder Erzeugen eines Objektes ) an \acrshort{SNS}  \autoref{par:sns}, \acrfull{SQS} \autoref{par:sqs} oder Lambda schicken kann. \glqq Buckets\grqq\ sind Verzeichnisse auf der höchsten Ebene des Verzeichnissystems. Ein Objekt ist eine Kombination von Daten, Metadaten und eines Keys, der innerhalb des Buckets eindeutig ist.


\begin{wrapfigure}{l}{0.16\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/Database_GRAYSCALE_AmazonDynamoDB.eps}
\end{wrapfigure}
\paragraph{DynamoDB} ist eine NoSQL Datenbank. Ihre Tabellen bestehen aus Items ( Zeilen ) und deren Attributen ( Spalten ). Die Datenbank hat laut \acrshort{AWS} unendliche Datenkapazitäten und der Datenverkehr ist unbegrenzt. 
Durch automatische Skalierung mindert sich die Leistung nicht. Bei der Änderung eines Zeilenwertes in DynamoDB ist die Konfiguration eines Anstoßes der Lambdafunktion möglich.

\begin{wrapfigure}{l}{0.10\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/Messaging_GRAYSCALE_AmazonSQS.eps}
\end{wrapfigure}
\paragraph{\acrfull{SQS}}\label{par:sqs} ist eine message queue. Sie erlaubt die Interaktion von mehreren Publisher und Consumer in einer \acrshort{SQS} und verwaltet automatisch den Lebenszyklus der Nachrichten und kontrolliert Auszeiten ( Time out ) oder individuelle Verzögerungen.

\begin{wrapfigure}{l}{0.10\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/Analytics_GRAYSCALE_AmazonKinesis.eps}
\end{wrapfigure}
\paragraph{Kinesis Streams} ist ein Service für Echtzeitverarbeitung von Datenstreams. Es wird für Logging, Datenimport, Metriken, Analytics und Reporting benutzt. Ein Kinesis Stream ist eine sortierte Folge von Datensätzen, die auf \glqq Shards\grqq\ verteilt sind. Diese definieren die Kapazität des 'Durchsatzes' ( Throughtput ) von einem Stream und können nach Bedarf vergrößert werden.


\newacronym{RDS}{RDS}{Relational Database Service}
\begin{wrapfigure}{l}{0.10\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/Database_GRAYSCALE_AmazonRDS.eps}
\end{wrapfigure}
\paragraph{\acrfull{RDS}} hilft bei dem Setup und Wartung von mySQL, MariaDB, Oracle, MS-SQL, PostreSQL und Amazon Aurora mit automatischer Bereitstellung ( provisioning ), Sicherung, patching, recovery, repair und Fehlererkennung. \acrshort{RDS} kann durch \acrshort{SNS} \autoref{par:sns} über eigene Events berichten.




\newacronym{SES}{SES}{Simple Email Service}
\begin{wrapfigure}{l}{0.10\textwidth}
	\includegraphics[width=0.9\linewidth]{./pics/aws/Messaging_GRAYSCALE_AmazonSES.eps}
\end{wrapfigure}
\paragraph{\acrfull{SES}} behandelt die Absendung und die Empfangsoperationen wie Spamfilterung, Virus Scan und Ablehnung nicht vertrauter Quellen. Emails können weiterhin in \acrshort{S3} gespeichert, an Lambda versendet werden oder eine \acrshort{SNS} Benachrichtigung auslösen.

\chapter{KOMA, eine Beispielanwendung}\label{sec:KOMA} 
Im Folgenden wird eine Beispielanwendung, unter Verwendung der in \autoref{chap:aws-serverless} genannten Entwurfsmuster, implementiert.
\newacronym{EQF}{EQF}{European Qualifications Framework}

Die Beschleunigung der Veränderungen in der heutigen Gesellschaft und der technologischen Landschaft prägt sich in Bildung und Beruf in so fern aus, dass die heutigen Rahmenlehrpläne nicht mehr fachlich, sondern an der Kompetenzentwicklung orientiert sind, um u.a Kompetenzprofile für Lerner zu erstellen. Es existiert bereits ein anerkannter Europäischer Rahmen\cite{EQF} für Kompetenzbildung: \acrfull{EQF}. Am Beispiel von Sachsen-Anhalt\cite{BildungsServerSachsen} werden diese Kompetenzorientierung auf die spezifischen Bedürfnisse der Schule beschrieben und die Unterrichsstunden entsprechend gestaltet.

Die Anwendung soll für die pädagogische Diagnostik und Intervention genutzt werden.
Ziel der Umsetzung ist es daher, auf einer Seite die von einem Schüler erworbenen und zu erwerbenden Kompetenzen und deren Niveau nachzuvollziehen. Andererseits bietet sie das Potenzial die Bildungs-, Unterrichts- und Stundenplanung zu unterstützen.\\

Kommt diese Anwendung in Bildungsinstitutionen zum Einsatz, dienen die Rahmenlehrpläne als Leitpfad für die Bezeichnungen und Anforderungen der Kompetenzen, wohingegen \acrshort{KOMA} für die Organisation der einzelnen Fachrichtungen oder Lehrveranstaltungen zuständig ist. Da der \acrshort{EQF} als Basis mit internationaler Anerkennung genutzt wird, den Kompetenzstand eines Individuums abzubilden, wird die Bildungsqualität international vergleichbar.

Den Kern von \acrshort{KOMA} bildet die Zuweisung von Aktivitäten auf vordefinierte Kompetenzen. Erstere lassen sich einzeln oder in einer Sequenz anordnen. Sequenzen werden in Lehrveranstaltungen zusammengestellt. So können Aktivitäten, Sequenzen und Kompetenzen als Gestaltungsmittel für Lehrveranstaltungen genutzt werden. 
%Die Auswertung der Ergebnisse der Schüler erfolgt durch eine Entit

%Das Modell verfügt von eine Figur um die erledigte Aktivitäten auszuwerten, nämlich Evaluation.

Das folgende Beispiel beschreibt einen fachorientierten Ansatz zur Gestaltung von Lehrveranstaltungen:\\
Das Fach \glqq Web Computing \grqq\ lässt sich mit einer Sequenz von Lernaktivitäten ( Unterrichtseinheiten ) gestalten. Die zu behandelnden Themen erfordern grundlegendes Wissen und Fertigkeiten wie das Beschreiben von Kommunikationsprotokollen und Bash Scripting. Dabei ist zu beachten, dass Wissen und Fertigkeiten kumulativ wachsen und damit aufeinander aufbauen.

Im Gegensatz zu dem fachorientierten Ansatz wird nun der kompetenzorientierten Ansatz erläutert:
Das Kompetenzmodell differenziert unterschiedliche Kompetenzen in vielfältigen Zusammensetzungen. Ihre Fertigkeiten und/oder Wissen werden während der  Lernaktivitäten, bei der die Auswahl von Themen freigestellt ist, erworben.Durch die Sequenzierung von Lernaktivitäten baut sich das Kompetenzmodell aus.


\subsection{Anforderungsanalyse}
Die Auflistung \autoref{list:koma-requirements} stellt einen für diese Arbeit angepassten Ausschnitt der Anforderungen für \acrshort{KOMA} dar:

\begin{itemize}\label{list:koma-requirements}
	\item Mit dem \acrshort{EQF} vergleichbare Kompetenzdefinitionen
	\item Berücksichtigen zukünftiger Erweiterungen 
	\item Abrufbarkeit durch den Browser 
	\item Private Datenspeicherung u.d Login
	\item Ertragen von großen Nutzlastschwankungen
\end{itemize}

\subsection{ER-Modell} Aus der Beschreibung von \acrshort{KOMA} \autoref{sec:KOMA} ergibt sich folgendes Modell. \autoref{list:koma-requirements}
\begin{figure}[h]
	\centering
	\includegraphics[scale=1]{./pics/koma-er-concept.eps}
	\label{pic:koma-er-concept}
	\caption{Entity-Relationship Modell für KOMA}
\end{figure}

Dieses ER-Diagramm \autoref{list:koma-requirements}  definiert die Beziehungen zwischen den in \autoref{sec:KOMA} beschriebenen Konzepten. Eine Kompetenz ( Competence ) besteht aus Fertigkeiten ( Skill ), die in einer Lernaktivität ( LearningActivity ) erworben werden. Die Letztere gehört zu einer Sequenz von Lernaktivitäten ( LearningSequence ). Erworbene Kompetenzen können nach Klassenstufen und Fächern aufgerufen werden, damit ein Kompetenzstand abgeleitet werden kann. Das Modell ermöglicht die Gestaltung von \acrshort{EQF}-konformen Kompetenzprofilen ( CompetenceModel ).



\subsection{Komponentenübersicht}
\label{sec:components}

Um einen Anhaltspunkt zu geben, werden hier die Softwarekomponenten beschrieben.

Bei dem Aufruf der Website im Browser präsentiert sich ein \glqq Sign in\grqq\ Knopf zum Einloggen und verschiedene Möglichkeiten zur Formulierung einer Abfrage. Diese ist in einem \acrshort{S3} Bucket als statische Webseite gelagert.
Wird der Knopf zum Einloggen gedrückt, fordert eine Weiterleitung ( mit dem dargestellten Schlüssel ) die Authentisierung des Benutzers an. Mit der erfolgreichen Operation kehrt die Nutzeransicht mit einem \glqq Token\grqq\ auf die Webseite zurück. Der erhaltene Token wird als Autorisierung-Parameter in dem \glqq HTTP Request Header\grqq\ mit den nächsten Anfragen an das Back-End geschickt.

\newacronym{URL}{URL}{Universal Resource Locator}
Nach dem Login kann der Browser durch Absenden der nächsten Anfragen seinen Token zur Überprüfung übergeben. Die \acrshort{API} Gateway empfängt die Anfragen und transponiert deren Parameter, um zunächst die entsprechende Lambdafunktion synchron aufzurufen. Da die \acrshort{API} nach \acrshort{REST} entworfen ist, werden die Lambdafunktionen nach der \acrshort{HTTP}-Methode und der \acrshort{URL} abgebildet.

Dieser Loginprozess entspricht dem in  \autoref{sec:federated-identity} beschrieben Federated Identity Muster.

Eine Anfrage an die \lstinline|GET https://<host>/page/{individual}| \acrshort{URL} führt die Lambdafunktion \glqq OWL Parser\grqq\ aus. Die Funktion liest die Datenbasis von S3 \glqq OWL Storage \grqq\ und extrahiert den Wert des \lstinline|{individual}|-Parameters, um eine Antwort zu generieren. Diese abstrahierte Zuweisung von \acrshort{URL}s auf Back-End Dienste entspricht einem \acrshort{REST} Ansatz. Dagegen erwartet die \lstinline|POST https://<host>/sparql| \acrshort{URL} eine Abfrage im \glqq Request Body\grqq\ der Anfrage mit dem Key \glqq Query\grqq\ , um sie auf der oben genannten Datenbasis auszuführen. Dabei unterstützt die Java Bibliothek Jena ARQ\cite{jenaARQ}


\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.60]{./pics/static-web-hosting.eps}
		\caption{KOMA Components}
		\label{pic:koma-components}
	\end{center}
\end{figure}

\section{Umsetzung}
\label{chap:impl}
Die grundlegende Vorgehensweise bei der Umsetzung dieser Webanwendung gliedert sich zunächst in die Datenspeicherung und deren Analyse bzw. Auswahl. Als Zweites wird zwischen dem Entwurf mit den oben vorgestellten Serverless Architekturmustern und Technologien und deren Implementierung iteriert, um ein schnelles Feedback zu erhalten.

\subsection{Datenspeicherung- Analyse und Auswahl}
Die Gestaltung von Kompetenzmodellen und deren zukünftige Weiterentwicklung hängt stark von den spezifischen Bedürfnissen der jeweiligen Schulen ab. Die möglichen Erweiterungen oder Anpassungen des Modells stellt die Benutzung des einer relationalen Datenbank für \acrshort{KOMA} in Frage. In der folgender Tabelle werden die Eigenschaften von relationalen mit ontologischen Schemas verglichen.

%@Pre-Dev--> Tabelle 
\begin{table}[h]
	\caption{Vergleich relationalem mit ontologischem \autoref{subsec:ontology} Schema}
	\centering{}
	\begin{tabular}{ccc}
		\noalign{\vskip\doublerulesep}
		Eigenschaft & Relational & Ontologisch \tabularnewline[\doublerulesep]
		\hline\noalign{\vskip\doublerulesep}
		Weltannahme & Existiert nur & Existiert mindestens \tabularnewline[\doublerulesep]
		\noalign{\vskip\doublerulesep}
		Individual & muss Unique & kann >= 1 \tabularnewline[\doublerulesep]
		\noalign{\vskip\doublerulesep}
		Info & Ableitung = x & ja \tabularnewline[\doublerulesep]
		\noalign{\vskip\doublerulesep}
		Oritentation & Data & Bedeutung \tabularnewline[\doublerulesep]
		
	\end{tabular}
\end{table}

Das ausgewählte Datendarstellungsformat ist das ontologische Schema, da es den Fokus auf Erweiterbarkeit und semantische Konzepte legt.
Im \glqq Semantic Web\grqq\ profitieren \glqq Linked Data Driven Web Applications\grqq\ von den vernetzten Datenbanken.
\cite{W3C}


\newacronym{W3C}{W3C}{World Wide Web Consortium}
Das \glqq Semantic Web\grqq ist eine Erweiterung des herkömmlichen Web, in der Informationen mit eindeutigen Bedeutungen versehen werden\cite{ontoWhat2}. Das \acrfull{W3C} spezifiziert eine Zusammenstellung von Standards und best practices für die Mitteilung von Daten und deren semantischer Darstellung.\cite{sparqlLearn}.
\newacronym{OWL}{OWL}{Web Ontology Language}
Diese Bedeutungen werden für Maschinen durch Ontologien dargestellt, welche in \glqq .owl \grqq\ Dateien gespeichert werden.\cite{W3C}

%\begin{figure}[h]
%	\centering
%	\includegraphics[width=0.8\textwidth]{pics/semantic_web_technology_stack.eps}
%	\caption{Überblick von Semantic Web Stack}
%	\label{fig:semantic-web-stack}
%\end{figure}


%@Def
Eine Ontologie\label{subsec:ontology} ist eine formale Spezifikation über eine Konzeptualisierung \cite{ontoWhat}. Die Denotation der dargestellten Signifikanten lässt sich durch ihre weltweit eindeutigen Präfix identifizieren z.B: \lstinline|PREFIX owl: <http://www.w3.org/2002/07/owl#>|  \cite{W3C}. Deren Beziehungen können zu externen Ontologie-signifikanten verweisen und dadurch ein Consensus über Begrifflichkeiten erreichen. 


Der Entwurf der Ontologie wurde nach Ontology-Engineering-101 durchgeführt:

Während der Umsetzung wurde Protégé \cite{Protégé} als unterstützende Anwendung benutzt.

Um bereits vorhandene Technologien zu nutzen,
wurde ein aktueller öffentlicher graphischer ontologischer Entwurf\cite{ontoMoodle} ( siehe  \autoref{fig:competence-ontology} ), der in Moodle mit einer relationalen Datenbasis und PHP umgesetzt wurde, untersucht.

Eine Implementation dieser Ontologie ist jedoch nicht von Watson\cite{Watson} und LOD\cite{LOD} auffindbar.

\begin{figure}[h]
	\centering
	\includegraphics[angle=270]{pics/competency-ontology.eps}
	\caption{Kompetenzontologie}
	\label{fig:competence-ontology}
\end{figure}


Der Entwurf und seine Dokumentation lassen freie Interpretation über Begriffe und deren Zweck, z.B \glqq isComposedOf\grqq, \glqq subsumes\grqq. Ein Standard zur graphischen Darstellung ist zur Zeit noch nicht anerkannt. Graphische Benutzeroberflächen zur Darstellung und zum Entwurf von Ontologien sind derzeit entwickelt, z.B. Graphol \cite{graphol}.

\newacronym{RCD}{RCD}{Reusable Competency Definition}
Daher folgt eine beispielhafte Erklärung, die auf den Anwendungsfall \acrshort{KOMA} eine angepasste und ergänzende Interpretation der dargestellten Terminologie des Entwurfs und der \acrshort{RCD} ( s.u. ) liefert.

\begin{wrapfigure}{i}{0.36\textwidth}
	\includegraphics[width=0.9\linewidth]{pics/RCD.jpg}
	\caption{Reusable Competency Definition}
\end{wrapfigure}

Der \acrshort{EQF} wurde für die ontologische Darstellung beschrieben und bietet eine europäisch anerkannte Definition von Kompetenz, die \acrfull{RCD} \cite{eqfCompetency}. Diese ist jedoch nicht in einer veröffentlichen Datenbasis umgesetzt worden.


\newglossaryentry{Kompetenz}{name={Kompetenz},description={die bei Individuen verfügbaren oder durch sie erlernbaren kognitiven Fähigkeiten und Fertigkeiten, um bestimmte Probleme zu lösen, sowie die damit verbundenen motivationalen, volitionalen und sozialen Bereitschaften und Fähigkeiten, um die Problemlösungen in variablen Situationen erfolgreich und verantwortungsvoll nutzen zu können}}

Die zwei Leitmotive sind auf der einen Seite Kompetenzanforderungen, \glqq die festlegen, über welche Kompetenzen ein Schüler, eine Schülerin verfügen muss, wenn wichtige Ziele der Schule als erreicht gelten sollen. Systematisch geordnet werden diese Anforderungen in Kompetenzmodellen, die Aspekte, Abstufungen und Entwicklungsverläufe von Kompetenzen darstellen\grqq\ \cite{competence}. 

Auf der anderen Seite bildet die Definition von \Gls{Kompetenz} eine handlungsleitende Grundlage. Nach Weinert werden Kompetenzen als \glqq die bei Individuen verfügbaren oder durch sie erlernbaren kognitiven Fähigkeiten und Fertigkeiten, um bestimmte Probleme zu lösen, sowie die damit verbundenen motivationalen, volitionalen und sozialen Bereitschaften und Fähigkeiten, um die Problemlösungen in variablen Situationen erfolgreich und verantwortungsvoll nutzen zu können\grqq\ \cite{weinert2002leistungsmessungen}.

\newacronym{RDF}{RDF}{Resource Description Framework}
\newacronym{TURTLE}{TURTLE}{Terse RDF Triple Language}

Die bisherige Analyse des Domainproblems wird nun anhand von Protégé in einen \acrfull{RDF} Format bzw. \acrfull{TURTLE} beschrieben. \acrshort{TURTLE} besteht aus einer für Menschen lesbaren Syntax und kann sowohl Ontologien in \acrshort{OWL} als auch \acrshort{Sparql} Abfragen darstellen. 

Das folgende \autoref{lst:turtle-triple} zeigt eine beispielhafte Darstellung von ontologischen Fakten, den sogenannten \glqq Triples\grqq\ . Diese bestehen aus Subjekt, Merkmal und Objekt. Die erste Zeile lässt sich wie folgt interpretieren: dem Namen einer fiktiven Schülerin Alice ( Subjekt ) wird ein Merkmal in Form einer Kompetenzausprägung ( Property ) innerhalb eines Unterrichtsfachs, das in Unterrichtsreihen oder -einheiten sequenziert werden kann, wie z.B Mathematik II ( Objekt ). Diese Instanzen werden Individuals genannt.

\begin{lstlisting}[language=SQL,caption={Darstellung von Triples in TURTLE},label={lst:turtle-triple}]
:Alice :hasCompetency :Math_II .
:EvidenceRecord rdf:type owl:Class .

:actionPerformed rdf:type owl:ObjectProperty ;
	rdfs:domain :EvidenceSource ;
	rdfs:range :Action .
\end{lstlisting}

\newacronym{Sparql}{Sparql}{Protocol And RDF Query Language}
Um aus Ontologien Informationen zu entnehmen, wird die Abfragesprache \acrfull{Sparql} 
verwendet. Diese ähnelt der traditioneller SQL. 

Die einfachste Abfrage in Sparql wählt alle Triples von dem abgefragten Datenmodell ( oder Graph ) wie in  \autoref{lst:sparql-selectall} gezeigt wird.

\begin{lstlisting}[language=Sparql,caption={Sparql SELECT ALL},label={lst:sparql-selectall}]
SELECT * WHERE { ?s ?p ?o .}
\end{lstlisting}

Hilfsvariablen können deklariert werden, um Ergebnisse aus einem Triple als Parameter für das nächste zu benutzen. Die folgende Abfrage ließe sich wie folgt formulieren: \glqq Wähle alle Properties des Graphes und wähle alle dessen Subjekten mit Alice als Objekt\grqq\ . \\
\begin{lstlisting}
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX koma: <https://s3-us-west-2.amazonaws.com/ontology.thb.de/koma-complex.owl#>
SELECT ?x WHERE {
	?y rdf:type owl:ObjectProperty .
	?x ?y koma:Alice .
}
\end{lstlisting}

Wie in \autoref{sec:components} erwähnt wurde, werden Sparqlabfragen durch die \acrshort{API} Gateway für Lambda transponiert.


\section{RESTful API}
\label{sec:rest}
\newacronym{HTTP}{HTTP}{Hypertext Transfer Protocol}
\newacronym{CRUD}{CRUD}{Create, Read, Update, Delete}
Der Entwurf von einem benutzerfreundlichen \acrfull{HTTP} \acrshort{API} beinhaltet die Abstraktion von komplexer Geschäftslogik und Datenverarbeitung  in den vier Operationen \acrfull{CRUD}.

\newacronym{JSON}{JSON}{Javascript Object Notation}
Die Komplexität des darunterliegenden Datenmodells erlaubt einer \acrshort{REST} Schnittstelle nur einfache Abfragen zu formulieren.\cite{microAdv} Daher stellt \acrshort{KOMA} zusätzlich einen Sparql-Endpunkt für komplexe Sparql Abfragen zur Verfügung. Die letzte Zeile der \autoref{tab:rest} ist eine solche komplexe Abfrage.

\begin{table}[H]
	\caption{RESTful API}\label{tab:rest}
	\noindent 
	\centering{}
	\begin{tabular}{ccc}
		\hline
		\noalign{\vskip\doublerulesep}
		Methode & URL & Rückgabe\tabularnewline[\doublerulesep]
		\hline
		\noalign{\vskip\doublerulesep}
		GET & /ontology & Information über KOMA
		\tabularnewline[\doublerulesep]\noalign{\vskip\doublerulesep}
		\noalign{\vskip\doublerulesep}
		GET & /ontology/\{individual\} & RDF von Individual
		\tabularnewline[\doublerulesep]\noalign{\vskip\doublerulesep}
		GET & /page & Auflistung von Entitäten 
		\tabularnewline[\doublerulesep]\noalign{\vskip\doublerulesep}
		GET & /page/\{individual\} & Information über diesen Fakt
		\tabularnewline[\doublerulesep]\noalign{\vskip\doublerulesep}
		POST & /sparql & Abfragenergebnis
		
	\end{tabular}
\end{table}

AWS API Gateway ermöglicht die Definition, Konfiguration und das Importieren von Schnittstellen. Beispielsweise kann der Anfrageparameter in \lstinline|GET https://<host>/page/Alice}| mithilfe des Musters in  \autoref{lst:map-template} an den Key \glqq individual \grqq\ zugewiesen werden. Hier handelt sich um einen \glqq body mapping template\grqq\ für den Inhaltstyp ( content type ) \glqq application/json\grqq\ .

\begin{lstlisting}[language=Javascript,caption={API Gateway Request Mapping Template},label={lst:map-template}]
https://<host>/page/{individua}
...
{
"individual" : "$input.params('individual')"
}
\end{lstlisting}

Nachdem eine Anfrage eingetreten ist und deren Parameter transponiert sind, erfolgt ein synchroner Aufruf der zuständigen Lambdafunktion. Die Verwaltung dieser Instanziierung entspricht dem Priority Queue Muster in  \autoref{sec:priority-queue}, wobei die \acrshort{API} Gateway der Queue und die Lambdafunktion dem Consumer entspricht.
% Hier vtl. messaging channels ansprechen a- synch

Das folgende \autoref{lst:js-handler} zeigt die Implementierung einer Lambdafunktionsfassade, die für die oben genannte \acrshort{URL} zuständig ist. 

\begin{lstlisting}[language=Javascript,caption={Lambda Javascript Funktionsfassade},label={lst:js-handler}]
...
exports.handler = function (event, context, callback) {
	reqIndividual = event.individual; // check possible exception
	async.waterfall([createBucketParams
						, getS3ObjectBody
						, parseOntology
					],
					function (err, result) {
						if (err) {
							callback(res.createErrorResponse(500, err));
						} else {
						if (Object.keys(result).length === 0 && result.constructor === Object) {
							callback(null, res.createErrorResponse(404, "there was no result on the search"));
						} else {
							callback(null, res.createSuccessResponse(result));
...
\end{lstlisting}

Die zweite Zeile entspricht der Fassadensignatur von Lambda für Javascript. Der erste Parameter, \glqq event\grqq, enthält in diesem Fall Informationen über die ursprüngliche Anfrage. Der Zweite, \glqq context\grqq\, erlaubt den Zugang auf die Laufzeitumgebung von Lambda und kann definieren, ob die Ausführung erfolgreich ( \lstinline|context.success(Object result)| ), fehlerhaft ( \lstinline|context.fail(Error error)| ) oder beides ( \lstinline|context.done(Error error, Object result)| ) war. 

In der vierten Zeile befindet sich der Aufruf \lstinline|async.waterfall(...)|. Dieser entspricht dem Waterfall Muster dessen Verarbeitungsschritte in der  \autoref{pic:waterfall} dargestellt werden. 
Dieses Muster erlaubt es, eine Reihe von Funktionen so zu verketten, dass das Ergebnis einer Funktion der Eingabeparameter der Nächsten ist. Wenn ein Fehler in einer Funktion entsteht, hält der Wasserfall an. 

\begin{figure}[H]
	\begin{center}
	\includegraphics[scale=0.6]{./pics/aws/pattern-waterfall.eps}
	\caption{Waterfall Muster}
	\label{pic:waterfall}
	\end{center}
\end{figure}

Um die Wiederverwendbarkeit zu gewährleisten, ist die Abtrennung der Abhängigkeiten in Bibliotheken der Lambdafunktion sinnvoll. Dieser Ansatz wird von dem \acrshort{SOA}-Architekturstil \autoref{sec:soa} gefordert.


Bei einer Abfrage an die \lstinline|POST https://<host>/sparql| \acrshort{URL} werden die Abfrageparameter ohne die Konfiguration von \glqq body mapping\grqq\ weiter an die zuständige Lambdafunktion geleitet.

Die Funktion hinter dieser \acrshort{URL}, wie in  \autoref{lst:lambda-sparql-endpoint} gezeigt, ist in Java 8 implementiert. Sie fordert die Implementierung der Schnittstelle RequestHandler. Die Generics-Parameter definieren den Klassentyp der Anfrage und des Ergebnisses, wie es im Fall der Abbildung \glqq RequestClass\grqq\ als Anfrage und \glqq String\grqq\ als Ergebnis ist. 

Der Nutzer kann Umgebungsvariablen\label{lambda-env} bei der Konfiguration von Lambdafunktionen anlegen und während Laufzeit auf sie zugreifen, z.B in der Zeile 7 mittels \lstinline|System.getenv(StringConstante)|.

\begin{lstlisting}[language=Java,caption={Lambda Sparql-Endpoint},label={lst:lambda-sparql-endpoint}]
public class Handler implements RequestHandler<RequestClass, String> {
...
@Override
public String handleRequest(RequestClass input, Context context) {
	context.getLogger();
	request = input;
	return new Controller(System.getenv(ENV_BUCKET), Regions.US_WEST_2.getName())
		.executeQuery(request.getQuery(), request.getBucketKey());
}
\end{lstlisting}

Die Klasse \glqq Controller\grqq\ ( Zeile 7 ) benutzt die Jena ARQ Bibliothek, um Sparqlabfragen auszuführen. Ein Beispiel ihrer Benutzung wird in \autoref{lst:lambda-sparql-endpoint-controller} dargestellt. 

Die Abfrage an die Datenbasis lässt sich mit \lstinline| request.getQuery()| ( Zeile 8 ) aus dem Bodyparameter \glqq query\grqq\ extrahieren.

\begin{lstlisting}[language=Java,caption={Lambda Sparql-Endpoint-Controller},label={lst:lambda-sparql-endpoint-controller}]
ObjectMapper mapper = new ObjectMapper();
QueryResultWithMap resultWithMap =
new QueryResultWithMap();
Map<String, String> tmp;

Query query = QueryFactory.create(aQuery);
try (QueryExecution qexec = QueryExecutionFactory.create(query, model)) {

ResultSet results = qexec.execSelect();
	while (results.hasNext()) {
	tmp = new LinkedHashMap<>();

	QuerySolution soln = results.nextSolution();

		for(String v : results.getResultVars()){
			RDFNode node = soln.get(v);
			tmp.put(v, node.isResource() ?
						soln.getResource(v).getLocalName() :
						soln.getLiteral(v).getString());
			}
		resultWithMap.getBody().add(tmp);

	}
	toClient =  mapper.writeValueAsString(resultWithMap);
...
\end{lstlisting}

Nach der Ausführung der Abfrage ( Zeile 7 ) werden die Ergebnisse in Zeile 15 iteriert und anschließend wird eine Referenz zu einem \acrshort{JSON}-Objekt zurück geliefert.\\

Mit der bisher beschriebenen Implementierung der Webanwendung können Daten abgefragt und verarbeitet werden. Diese Ergebnisse stellen ein Feedback dar, womit Konzepte (  siehe \autoref{aspect} ) bewiesen, ausgewertet und weiterentwickelt werden können. % Weiter zur Auswertung Time to market etc.

%% ----------- hier fängt es mit dem Refactoring an

Ein wesentliches Merkmal von den oben beschriebenen Lambdafunktionen ist, dass sie für jeden Aufruf die komplette Datenbasis neu herunterladen. Für die Gebrauchstauglichkeit der Anwendung werden im Folgenden Verbesserungsansätze erläutert.

Caching zielt auf die Verbesserung der Performanz und Skalabilität eines Systems ab, in dem es die oft gelesenen Daten temporär zwischenspeichert. Daher können wiederholte Zugriffe auf die Ontologie in einem Cache gepuffert werden. Hierzu bietet \acrshort{AWS} \glqq ElastiCache\grqq\ als Serverless Dienst. 
\begin{figure}[H]
	\begin{center}
\includegraphics[scale=0.60]{./pics/aws/pattern-cache-shared.eps}	
\caption{Shared Cache Muster}	
\label{pic:shared-cache}
	\end{center}
\end{figure}
Es gibt zwei Typen von Software Cache: \glqq Shared-Cache\grqq\ und \glqq In-Memory\grqq\ \cite{patternsCloud}. Der Letztere teilt die Umgebung des Consumers ( Lambda in diesem Fall ) mit. Da die Laufzeitumgebung von Lambda ohne Vorwarnung wechseln kann und nur über nicht persistenten Speicher verfügt \cite{lambdaFaq}, lässt sich die In-Memory Cachevariante nicht konsistent implementieren.\\

Ein schnellerer Zugriff wird durch die Allokation eines Caches zwischen der Datenbasis und den Lambdafunktionen ( siehe \autoref{pic:shared-cache} ) gewährleistet. Da die Consumer den gleichen \glqq Snapshot\grqq\ der Daten abrufen, sinkt die Anzahl der inkonsistenten Ergebnisse.\cite{patternsCloud}\\

Mit der Benutzung der Anwendung werden voraussichtlich die \acrshort{OWL} Dateien größer und somit die Latenz bei Abfragen verlängert.

\newacronym{URI}{URI}{Universal Ressource Identifier}
Eine zusätzliche Maßnahme zur Optimierung des Datenzugriffs ist die Datenpartitionierung. Diese kann je nach Benutzungsmuster horizontal, vertikal oder funktional erfolgen.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.60]{./pics/parititioning.eps}	
		\caption{Partitionierung der Datenbasis}
		\label{pic:partitioning}
	\end{center}
\end{figure}
% ontoVerticalPartition < poor scales on triple stores
Im Folgenden wird die Anwendung als Beispiel zur Erklärung genutzt.\\ 
Bei der horitzontalen Datenpartitionierung wird die \acrshort{OWL} Datei nach \glqq Individuals\grqq\ aufgeteilt und in unterschiedliche Buckets einsortiert. Hingegen wird bei einer vertikalen Datenpartitionierung jeweils eine Tabelle für Subjekte, Merkmale ( Properties ) und für Objekte erstellt. DynamoDB eignet sich für diese Serverless Anwendung  als \glqq Key-Value Store\grqq\ , um als Keys die \glqq Individuals\grqq\ und als Values dessen \acrfull{URI}s darzustellen.\cite{ontoVerticalPartition}

Die funktionale Partitionierung richtet sich nach Benutzungsfällen oder Geschäftsprozessen ( bzw. Bounded Context ). Die \acrshort{OWL} Detei ließe sich beispielsweise nach der häufigsten Ergebnissen aufteilen.



Cloud Dienste werden oft in unterschiedlichen Datenzentren oder Regionen eingesetzt. Um die Verfügbarkeit, Performanz und Konsistenz\label{data-vorteile} zu maximieren und die Datenübertragungskosten zu minimieren, kann eine Master-Datenbasis mit erlaubten Lese- und Schreiboperationen und eine Subordinate-Datenbasis nur mit Leseoperationen definiert werden.\cite{patternsCloud}
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.60]{./pics/aws/master-slave.eps}
		\caption{Replizieren der Datenbasis}
		\label{pic:master-slave}
	\end{center}
\end{figure}

Der Master pusht ( one-way Synchronisierung ) die Daten an seine Subordinate-Repliken. Diese Segregation favorisiert Lesezugriffe und vereinfacht die Datensynchronisierung, da sie nur in einer Richtung erfolgen.
Bei angeforderter Auswahl der zu replizierenden Daten priorisiert man die statischen vor den dynamischen Daten.
Latenz verkürzt sich bei der Zuteilung einer Replik ( siehe  \autoref{pic:master-slave} ) in der physischen Nähe des Consumers.


Viele
\section{Single Page Application}
\label{sec:spa}

Da KOMA ohne Vorkenntnisse zu benutzen sein soll, lässt sich die Entscheidung über die Art der Benutzeroberfläche leicht treffen. Die milliardenfache Nutzung von Web Browsern macht sie zum Favoriten.


Die Web Anwendung ist für alle Rechenaufgaben verantwortlich, die im Browser sicherheitstechnisch keine Gefahr darstellen, um das Backend oder den Server möglichst wenig auszulasten. Deswegen bietet sich eine Single Page Application an. 
Die \acrshort{SPA} besteht aus einem einzigen HTML Dokument. Dadurch vereinfacht man die Konfiguration der Authentifizierung und unterbricht den Fluss der UI-Darstellung zwischen Seiten nicht.

Ein konfiguriertes Anfangsprojekt/Quickstart kann mithilfe von Initializr\cite{Initializr} oder JHipster\cite{Jhipster} schnell angelegt werden. Für die lokale Entwicklung der Webseite werden anhand von NodeJS und NPM folgende Bibliotheken als Abhängigkeiten verwaltet: Bootstrap als Stylescheet und jQuery als Javascript-Bibliothek.
Die Webseite wird statisch mittels S3 geliefert. Dies geschieht mit folgendem Befehl: 
\begin{lstlisting}[language=BASH, caption={Webseite veröffentlichen}]
$ aws  --region us-west-2 s3 website --index-document index.html --error-document error.html 's3://koma.thb.de'
\end{lstlisting} 

Da der Zugriff auf die Datenspeicherung gesichert werden soll, wird die Login-Funktionalität hinzugefügt. In  \autoref{pic:koma-components} kann eine Übersicht der nötigen Schritte zur Anmeldung bei AuthO, zur Authentisierung und zur Autorisierung erhalten.

Der Nutzer meldet sich im ersten Schritt mit dem importierten Script \lstinline|<script src="https://cdn.auth0.com/js/lock-9.min.js">| und der von \acrshort{KOMA} mit gelieferten Konfiguration ( siehe   \autoref{lst:authO-anmeldung} ) an. 

\begin{lstlisting}[language=JavaScript,caption={Auth0 Anmeldung},label={lst:authO-anmeldung}]

auth0Lock = new Auth0Lock(config.auth0.clientId, config.auth0.domain);

auth0Lock.getProfile(idToken, function (err, profile) {...}

\end{lstlisting}
\newacronym{JWT}{JWT}{JSON Web Token}
\newacronym{XHR}{XHR}{XMLHttpRequest}
\newacronym{JWS}{JWS}{JSON Web Signature}
Nach der erfolgreichen Anmeldung erhält der Nutzer einen \acrfull{JWT}, um ihn bei weiteren Anfragen kodiert ( in \acrfull{JWS} ) vorzuweisen. Dies geschieht mithilfe von der \acrfull{XHR} Schnittstelle. In diesem Fall wurde deren Implementierung von jQuery verwendet.

\begin{lstlisting}[language=JavaScript,caption={Remote Procedure Call mit XHR Schnittstelle},label={lst:xhr}]
$.ajaxSetup({
	'beforeSend': function (xhr) {
	xhr.setRequestHeader('Authorization', 'Bearer ' + localStorage.getItem('userToken'));
	...
\end{lstlisting}

Die Lambdafunktion, gekennzeichnet mit \glqq UserProfile\grqq\ , dekodiert den erhaltenen \acrshort{JWT} durch einen Schlüssel, der in Umgebungsvariablen ( siehe \autoref{lambda-env} ) angelegt wurde. Die Überprüfung erfolgt mit einer Abfrage an AuthO ( siehe \autoref{lst:verify} in Zeile 2 ).

\begin{lstlisting}[language=JavaScript,caption={Authentisierung in Lambda},label={lst:verify}]
var secretBuffer = new Buffer(process.env.AUTH0_SECRET);
jwt.verify(token, secretBuffer, function(err, decoded){
...
url: 'https://'+ process.env.DOMAIN + '/tokeninfo',
...
\end{lstlisting}

Dieses Vorgehen bei der Authentisierung ( siehe \autoref{pic:federated-identity} ) basiert auf dem Vertrauen zwischen Cloudanbietern. Der Nutzer kann für mehrere Anwendungen die gleichen Zugangsdaten benutzen. Die Anmeldung erfolgt über den Identitätsanbieter ( wie z.B Google oder Github ). 

Der autorisierter Zugriff kann nun gewährleistet werden, da die Verwaltung bzw. die persistente Speicherung von Nutzerprofilen möglich ist. 

\chapter{Auswertung}


\paragraph{Zur Skalabilität}
Die Partitionierung und das Replizieren von Datenbanken bringt zwar Vorteile ( wie in \autoref{data-vorteile} gezeigt wurde ), aber auch Herausforderungen bei der Synchronisation und Konsistenz der Daten mit sich. Dies geschieht auf Grund des konsistent zu haltenden Zustandes der Datenbanken.

Die Relevanz und Bedeutung der Daten hängt von dem Standpunkt ab. Z.B ein Schüler möchte schnell zu erfahren, ob der Hochladevorgang seiner Arbeit erfolgreich war ( Schreibzugriff vorziehen ). Ein Professor überprüft, ob alle Schüler ihre Arbeit hochgeladen haben ( Lesezugriff vorziehen ). Daher lässt sich eine technologisch orientierte Strategie unklar definieren, da weder alle Faktoren bekannt, noch beachtet werden können. 


Die Unmöglichkeit, alle Perspektiven zu berücksichtigen, erfordert eine Entscheidung ob ein Service entweder eine Funktion oder eine Datenbank ist; auf die Gefahr hin, dass nicht alle Benutzerinteressen umgesetzt werden, obwohl der Begriff Service in \glqq \acrlong{SOA}\grqq\ als ein Mehrwert für die Benutzer verstanden wird. 

Um eine möglichst hohe Performanz zu erzielen, wird die Anwendung entsprechend der Benutzungsmuster gestaltet. Die funktionale Datenbankpartitionierung erfüllt, wenn korrekt implementiert, diese Forderung.

Da ein Event beispielsweise eine Interaktion zwischen dem Kunden und der Anwendung repräsentiert, eignet sich die \acrshort{EDA} für die Steuerung von Benutzungsfällen besonders gut. Deren Orchestrierung lässt sich mittels einer endlichen Zustandsmaschine definieren und einem Petrinetz darstellen, in dem Events die Kanten und \acrshort{FaaS} die Ecken sind. Dieser Ansatz ähnelt dem Domain getriebenen Entwurf ( Domain Driven Design \cite{ddd} ), in dem Benutzungsfälle in Kontextgrenzen ( Bounded Context ) zusammengefasst werden.


\newacronym{JEE}{JEE}{Java Enterprise Edition}
\paragraph{Frameworks und FaaS}
Frameworks helfen bei der Entwicklung von komplexen Systemen, in dem sie Abstraktionsschichten hinzufügen und damit komplexe Berechnungen wie bei der \glqq Dependency Injection\grqq\ von \acrfull{JEE} übernehmen. 

Für \acrshort{KOMA} wurde kein Framework benutzt, da die Implementierung der Funktionen dem \acrshort{SRP} folgte und der Abstraktionsschichten nicht bedurften. Hingegen wurden die unten beschriebenen Tests durchgeführt, um die Verwendbarkeit von Frameworks innerhalb einer Lambdafunktion auszuwerten. 

Das ausgewählte Framework ist Apache Jena \cite{fuseki}, es wird als ein eingebetteter Server eingesetzt. Dieser unterstützt den Ausbau von Semantic Web und Linked Data Anwendungen.

Das \autoref{lst:fuseki} zeigt die vorgenommene Konfiguration für den Aufbau des Servers. Er wird während des Tests die schon vorgeladene \acrshort{KOMA} Ontologie durchgehen und ausloggen, um anschließend wieder zu stoppen.

\begin{lstlisting}[language=Java,caption={Embedded Server in Lambda},label={lst:fuseki}]
Dataset ds = DatasetFactory.createTxnMem();
server = FusekiServer.create()
.setPort(3030)
.add("/dataset", ds)
.build();
server.start();

\end{lstlisting}

% RES
Die folgende Grafik zeichnet die Ergebnisse der oben genannten Tests auf. 

\begin{figure}[H]
	\centering{}
	\includegraphics[scale=0.60]{./pics/cold-fuseky.eps}
	\caption{Ausführungszeiten für Fuseki Server in Lambda }
\end{figure}

Die Ergebnisse zeigen, wie sich die \acrshort{JVM} in der Lambdalaufzeitumgebung initiiert ( siehe \autoref{lambda-cold-warm} ). Da die Laufzeitumgebung für jede Anfrage eine neue Lambdafunktion instantiiert, muss der Server neu gestartet werden. Hierzu beweist die Grafik, dass \acrshort{IaaS} und \acrshort{PaaS} besser für längerfristige Prozesse als Lambda geeignet sind ( siehe \autoref{lambda-yes-no} ). 

Die bereitgestellte Speicherkapazität beschleunigt die Ausführung und dadurch verkürzen sich die Antwortzeiten. In diesem Szenario nutzt die Transaktionsverwaltung und die \glqq In-Memory\grqq\ Caching des Servers nicht.

Bei zu niedrigen vorkonfigurierten Speicherkapazitäten sind folgende Fehler zu beobachten:

\begin{table}[h]
	\centering{}
	\begin{tabular}{ccc}
		\noalign{\vskip\doublerulesep}
		Ressourcen ( MB ) & Ausführungszeit ( ms ) & Benutzte Speicher ( MB ) \tabularnewline[\doublerulesep]
		\hline
		\noalign{\vskip\doublerulesep}
		256 & 26100 & 101 \tabularnewline[\doublerulesep]
		\noalign{\vskip\doublerulesep}
		\noalign{\vskip\doublerulesep}
		128 & Fehler & java.lang.OutOfMemoryError \tabularnewline[\doublerulesep]
	\end{tabular}\label{lambda-out-of-memory}
\caption{Tests mit Frameworks in Lambda Ergebnisse}
\end{table}

Allerdings verursacht die Rekonfiguration keinen neuen Einsatz ( Deployment ), damit werden Ausfallzeiten vermieden. 

An dieser Stelle empfiehlt es sich, dass in \autoref{legacy-api-proxy} vorgestellte Legacy API Architekturmuster zu benutzen. Somit würden Anfragen, die eine Transaktionsverwaltung benötigen, an den Server weitergeleitet und die Latenz verkürzt.

Durch die Ersetzbarkeit der \acrshort{FaaS} ist hier erreicht, dass die Entwickler und die Anwendung von der darunterliegenden Technologie entkoppelt werden.% Agnostic 
 
Die \autoref{fuseki-arq} zeigt die Ausführungszeiten der Abfrageverarbeitung des Servers und der Jena ARQ Bibliothek. 
\begin{figure}[H]
	\centering{}
	\includegraphics[scale=0.60]{./pics/fuseki-arq.eps}
	\caption{Ausführungszeiten für Fuseki und Jena ARQ }
	\label{fuseki-arq}
\end{figure}

Die serverlose Variante ( Jena ARQ, in Orange ) ist erst ab der zweiten Ausführung deutlich schneller als mit Fuseki ( in Blau ).


Sowohl zwischen der 5. und der 7. als auch der 10. und 11. Ausführung steigt die Latenz. Nach Ergebnissen von Herrn McGrath und Brenner lässt sich dieses Phänomen auf \glqq kalte Startzeiten\grqq\ ( siehe \autoref{lambda-cold-warm} ) zurückführen . Dabei zeigten Google Cloud Funktions und Lambda deutlich weniger Schwankungen bei den Latenzmessungen. \cite{servPerform}


\paragraph{Große Bibliotheken}
Die gebaute JAR Datei der oben erwähnten Lambdafunktion, Jena ARQ, beträgt 19 MB. Die Ladezeiten verlangsamen sich, je größer die auszuführende Lambdafunktion ist \cite{lambdaBibliothek}. Wissenschaftliche Bibliotheken wie \glqq SciPy\grqq\ ( für die Programmiersprache Python ) übersteigen die maximale Größe einer Lambdafunktion ( 50 MB ).
Daraus ergibt sich, dass eine Verwaltung für große Bibliotheken gerade dann nötig ist, wenn auch der Benutzungsfall sich nicht für containerbasierte Anwendungen gut eignet. 

Das Verwaltung von großen Bibliotheken wird derzeit zwar nicht von \acrshort{AWS} Lambda unterstützt, dafür aber von \glqq Pipsqueak\grqq\ ( ein package-bewusst Berechnungsplattform für OpenLambda \cite{lambdaBibliothek} ). Die Autoren schlagen den Ausbau einer \glqq Shared-Cache\grqq\ innerhalb der Lambdalaufzeitumgebung vor, die während der Laufzeit Bibliothekenabhängigkeiten an Lambdafunktionen liefert.


\paragraph{DevOps Frameworks}\label{devops-critic}
Die Anzahl von Diensten bzw. Funktionen kann in einem komplexen System unübersichtlich werden. Entsprechend steigt der Aufwand bei Deployments, der Verwaltung und der Kohäsion von Abhängigkeiten, sowie bei der Koordination des Entwicklerteams ( z.B. Wer entwickelt was wann? ). 

Folgende \autoref{deploy-comparison} \cite{servStatus} zeigt, dass die hohe Granularität des Einzatzes der Serverless Architekturen Automatismen unweigerlich mit sich führt.

\begin{table}[H]
	\centering{}
	\begin{tabular}{c | c c c c}
		\noalign{\vskip\doublerulesep}
		& Vor Ort & VMs & Containers & Serverless \tabularnewline[\doublerulesep]
		\hline
		\noalign{\vskip\doublerulesep}
		Bereitstellungszeit & bis Monaten & Minuten & bis Minuten & Millis. \tabularnewline[\doublerulesep]
		\noalign{\vskip\doublerulesep}
		\noalign{\vskip\doublerulesep}
		Benutzung & Gering & Hoch & Hoher & die Höchste \tabularnewline[\doublerulesep]
		\noalign{\vskip\doublerulesep}
		Ladegranularität & Keine & Stunden & Minuten &  Blöcke von Millis.\tabularnewline[\doublerulesep]
	\end{tabular}
\caption{Vergleich zwischen  von Verwendung und Deployment }
\label{deploy-comparison}
\end{table} 

Diese Schwierigkeit macht die Deploymentframeworks wertvoll, da sie nicht nur die oben genannten Probleme ansprechen, sondern auch den Umgang mit anbieterspezifischen Sicherheitsrichtlinien vereinfachen. Dazu sind \glqq Serverless Framework\grqq\ und \glqq Zappa\grqq\ die bekanntesten Beispiele.

\acrshort{AWS} ermöglicht es, den Entwicklungsstand der Dienste zu bezeichnen, z.B \glqq Dev\grqq\ oder \glqq Produktion\grqq\ und Dienste in Browsern einzeln zu testen. Dies ist nur bedingt ausreichend, denn Systemtests sind noch nicht möglich. Somit gewinnt die Deployment-Strategie an Bedeutung.



\paragraph{Zur Entwicklung}
Die starke Komponentisierung und Dezentralisierung von Software, die Variabilität von Programmiermodellen, Frameworks, Tools, Sprachen und deren Entwicklungsumgebung erhöht die Komplexität des Entwicklungszyklus und weckt einen Bedarf an Tools zur Automatisierung von Deployment, Konfiguration und Tests. Ein klar definierter Handlungsplan bei der Softwareentwicklung  erleichtert das Abstrahieren von zu bearbeitenden Details.

Die DevOps Kultur gibt dazu Hilfestellungen. Neben dem Entwurf der Softwarearchitektur ist es nötig, um deren Umsetzung innerhalb des zeitlich vorgegebenen Rahmens zu gewährleisten, eine zum Projekt passende DevOps Strategie aufzustellen.
Um einen Vorteil aus den neuen Technologien zu ziehen, ist die Recherche nach schon existierenden DevOps Frameworks besonders wichtig. Ihre Integration in die DevOps Strategie sind einer agilen Entwicklung dienlich.


\paragraph{Zu Serverless} Die unterschiedlichen Interpretationen des Begriffs Serverless führen mitunter zu kreativen Ansätzen wie die Containerisierung einer Lambdalaufzeitumgebung. Dies ist vorteilhaft, weil dadurch alle Programmiersprachen unterstützt werden können.


\paragraph{Kosten und Performanz zwischen Lambda und Server}
Auf der kleinsten Ebene rechnet Lambda nach zeitlichen Abschnitten von 100 ms ab. Da viele \acrshort{RPC} kürzer als 100 ms lang leben \cite{rpcTime}, wird laut den Autoren von \cite{lambdaOpen} ein 3.7 fache Zunahme an Abrechnungen verzeichnet.

Da die \acrshort{PaaS} und \acrshort{IaaS} pro Stunde abgerechnet werden, \acrshort{FaaS} hingegen pro Anfrage, ergibt sich daraus, dass der Preis und die Performanz je Anfrage, umgekehrt proportional zu ihrer Anzahl ist.


\paragraph{Nachteile} 
Da HTTP und Lambda zustandslos sind, können die Sitzungen der Nutzer derzeitig nur mit Hilfe von Datenbanken implementiert werden. Interaktionen, die auf älteren basieren, wurden im Front-End berücksichtigt. Obwohl Zustände von Lambdafunktionen innerhalb eines \glqq Workers\grqq ( siehe \autoref{lambda-arch} ) sichtbar sind \cite{lambdaOpen}, wird die Kontrolle auf diese nicht gewährleistet.

Der Einsatz von großen Mengen von Quellcode verlangsamt die Ladezeiten des Servers ( siehe \autoref{lambda-arch} ), u.d. verschlechtert sich die Latenz der HTTP-Response.

Die Hardwareressourcen von Lambda skalieren zwar vertikal, aber nur proportional. Entsprechend werden diese nicht genutzt, aber abgerechnet. 

Die Latenz bei der Bereitschaft auf neue Anfragen ist bei Lambda höher als bei \acrshort{PaaS}, daher sind Mechanismen zur Optimierung von Antwortzeiten nötig, z.B: eine periodische Ausführung zur Wiederverwendung der Lambdalaufzeitumgebung, oder das Ableiten einer Message Queue ( Nachrichtenschlange ) von einer überlasteten \acrshort{PaaS} Anwendung zu Lambdafunktionen.

Es besteht ein Lock-in Risiko, wenn die Portierung von Quellcode auf unterschiedliche Cloudanbieter nicht im Voraus eingeplant wurde.

Der Kontrollverlust über das Verhalten der Serverless Dienste kann die Entwurfsentscheidungen erschweren.


Die AWS-Umgebung lässt das Debuggen von Lambdafunktionen nicht zu, obwohl Werkzeuge zum lokalen Testen und Debuggen diese Umgebung emulieren.

% revise
Je spezifischer sich die Anforderungen gestalten, desto mehr Eigenschaften der zugrundeliegenden Technologie sind zu beherrschen, z.B.: eine Benutzer definierte Erweiterung der Funktionalität einer Datenbank durch Lambda.

\paragraph{Vorteile}
Die automatische Skalierung erleichtert das Wachstum einer Webanwendung, denn sowohl deren Erfolg als auch die Anzahl von Anfragen ist nicht einfach vorherzusehen.

Durch die garantierte Lieferung von Nachrichten ( siehe \autoref{par:sns} ) können auch stark skalierte 
Webanwendungen von der Fehlertoleranz profitieren.

Der zeitliche Aufwand bei dem Planen von Ressourcenbereitstellung hat sich, wegen der automatischen Skalierung und fast exakten nutzungsabhängigen Abrechnung, aufgelöst.

So lange ein Architekturentwurf vorhanden ist, können sich die Entwickler auf den Kern des Quellcodes konzentrieren.



\chapter{Ausblick}

Da der Architekturentwurf komplexer wird, bietet sich die Implementierung von unterstützenden Werkzeugen an, die einen kohärenten Entwurf z.B. durch Petrinetzmodellierung erleichtern.


%\paragraph{RESTful UI}
Die Komposition von unbekannten Inhalten in einer Benutzeroberfläche, wie es der Fall bei einer \glqq Linked Data Driven\grqq\ Webanwendung ist, lässt sich mittels \acrshort{REST} Schnittstellen gestalten. Da Dienste von Drittanbieter aufgerufen und deren Inhalte eingebettet werden können. Die Konfiguration ihrer Darstellung kann mit Parametern in der Anfrage festgelegt werden.


%\paragraph{in wie fern erleichtert Serv. die Umsetzung Tatsächlich}
Der Bedarf an Werkzeugen für die Entwicklung, den Einsatz, das Testen usw. besteht, wie in \ref{devops-critic} erläutert wurde, auch mit dem Serverless Ansatz weiterhin.


%\paragraph{Zukunftsperspektiven und Trade-Offs}
%Ontologien habe potenzial dieses Falles hinaus 
Die Vereinigung von Edge- mit Cloud-Computing durch die Verwendung von \acrshort{FaaS} kann ein neues Potenzial für die Entwicklung von IoT darstellen. Der Begriff \glqq Edge-Computing\grqq\ bezeichnet die Verlagerung von Rechenleistung, Anwendungen, Daten und Services an die Endpunkte eines Netzwerkes \cite{edge}. Diese Verlagerung wurde bei der Umsetzung von \acrshort{KOMA} in \autoref{sec:spa} in Form einer \acrshort{SPA} implementiert. 



%\paragraph{Fazit} 

% revise 
Die starke Entkopplung ( siehe \autoref{sec:eda} ) von Diensten, die aus der Umwandlung von einer monolithischen in eine dezentralisierte Architektur entsteht, bringt mehr Komplexität, mehr Flexibilität und die Entkopplung des Entwicklers von der zugrundeliegenden Technologie mit sich. Daher gewinnt die Entwurfsphase eines Projekts bei Serverless Architekturen an Bedeutung, um die Kohäsion von Diensten zu gewährleisten. Als Konsequenz tritt die Modellierung und Entwicklung der Problemdomain in den Vordergrund.

%\paragraph{wie lässt sich bei AWS eine möglichst höhe flexibilität erzielen}

An dieser Stelle ist es hilfreich zwischen einer zeitlichen und einer technologischen Flexibilität zu differenzieren. Die Zeitliche kann erreicht werden, in dem die Kernfunktionalität einer Anwendung in \acrshort{FaaS} Dienste kapselt, um einen konzeptionellen Beweis durchzuführen; die Technologische durch die oben vorgestellten Architekturentwurfsmuster ( siehe \autoref{chap:aws-serverless} ) . Da die unter \acrshort{EDA} integrierten Dienste von einander stark entkoppelt sind, lassen sie sich einfach aggregieren.




\lstlistoflistings

\listoftables

\bibliographystyle{alpha}
\bibliography{sources}


\end{document}


%So dass auch die Benutzer von \acrshort{KOMA} solche Abfragen stellen können wird ein \glqq Sparql-endpoint\grqq mit Hilfe von Apache Jena ARQ, ein Sparql-Engine, zur Verfügung gestellt. 

%Dieser Sparql-Endpoint entspricht der Repositoryschicht der Anwendung und wird nach Anfrage von der Ontologie in S3 mittels Sparql JSON Objekte zurückliefern.
%Eine Lambdafunktion arbeitet als Schnittstelle \ref{lst:lambda-interface} zwischen die ARQ Bibliothek, den Client und die darunterliegende Infrastruktur.

%Die beide oben beschriebenen Funktionen liefern einen JSON Objekt zurück.
%Dieser Endpunkt unterstützt nicht nur GET-Abrufe, sondern auch POST-Anforderungen mit einer Nutzlast.Unter der verfügbaren SparQL endpoints Implementierungen


%Um den Datenmodell möglichst simpel programmatisch abzufragen wird zunächst dessen Schnittstelle\ref{sec:rest} definiert. 

%\subparagraph{JEE.war} \glqq And\grqq Test vs SRP Identifizieren der Concerns und ihre Trennung: 

%\subparagraph{Einloggen} Login beispiel: user + password + userData -> user + passord -> uuID -> userData refactor and share common code


%Autorisierung und Authentifizierung. Einleitung

%Auth0 bietet Authentifizierung as a Service an. Der Benutzer erhält einen JSON Web Token JWT und schickt ihn Encoded JSON Web Signature JWS oder JSON Web Encription zur Anwendung mit.
%Mit wenige Konfigurationsschritte kann man die Benutzer Authentifizieren. 


%Einloggen: 0Auth Google gibt token, der wird in Lambda überprüft, Session in oauth.com verwaltet


%\subparagraph{Dynamo DB} Funtion: Read + Write + updateS3 zu Split S3, Split R/W 

%Datenspecherung Architektur:
%DynamoDB: speichert :individual als Schlussel und seine relative URL
%Ś3: speichert die .owl Dateien.

%Lambda Funktion: Maps zwischen S3 und DynamoDB.



%@Glossar
%ontology: explicit, formal specification of a shared conceptualization
%Semantic Gap: Diferent ontologies to representate/ describe the same thing
%Polisemy ptoblem

%Formale Darstellung von Wissen durch eine Menge von Konzepten innerhalb eines Domänes und dessen Beziehungen -zwischen Konzepten-. way to mix together different descriptive vocabularies in a consistent way. Vocabularies can be created by distinct communities and groups as appropriate and mixed together as required, without needing any centralized agreement on how terms from different vocabularies can be written down in XM


%p.6 Studies in computational intlligen Ontologies: Level 4 SaaS :Scalable, Configurable, and Multitenant

%https://de.slideshare.net/UscholdM/ontologies-and-db-schema-whats-the-difference
%https://www.youtube.com/watch?v=bGPVCkuKTo4
%https://www.youtube.com/watch?v=n1hwsclr0Eg

%https://db-engines.com/de/system/Amazon+DynamoDB;GRAKN.AI;H2
%https://stackoverflow.com/questions/36255919/can-i-use-an-ontology-as-database-and-store-data-within-it

%nosql: https://de.wikipedia.org/wiki/NoSQL

%@Glossar
%Semantics: relationships between signifiers
%De-notation: precise literal meaning of signifier
%Con-notation: associated meanings of signifier


%Stand der Technik: 
%Vorgehensweise bei Traditionelle Webanwendungen:  
%Software Architektur: "What's important". Frühe, un-/schwer- veränderbare Entscheidungen.
%@Glossar: 
%Web Services are processes that expose their interfaces to the Web so that users can invoke them. %Facilitate service discovery and meaning encoded in schemas
%Design: Lambda Orchestrator -> Pool of Lambdas to use


%EventDriven Tasks: Lambda solves the polling problem by creating an on-demand response to particular events.

%Cron. Events: EC2 als behälter von Scripts, kostet auch ohne sie auszuführen. Fehlerhafte Scripts nicht einfach zu erkennen. Skallierung auch von Fehler. Permissions zu offen.
%Mit Lambda: the permissions can be much more narrowly applied, failures are much more easily noticed, deployments can be easily triggered, logs are aggregated in one place, and the underlying server management is handled by AWS.

%Heavy Processing: Um autoskalling zu vermeiden wegen z.B.Bildverarbeitung. So entkoppelt sich der Empfänger und der Verarbeiter und können mehr Requests angenommen werden. 

%Serverless API Gateway vermeidet api servers

%Selten verwendete Services. z.B <= 5 porZent average CPU t2.micro <~> 3x10hoch6 = 9dollar

%\subsection{Use Cases}
%next\cite{serverlessArchAWS}
%Application Backend: z.b Internet of Things IoT: push to S3, push queue to SQS and invoke Lambda.

%Data Procesisng and manipulation: pipeline of :collation and aggregation of data; image resizing;and format conversion.

%Real time processing and analitics: Ingestion of Data -> Kinesis Streams; if Batch size -> Process, Save, Discard -> Lambda

%Legacy Api Proxy: Extra RESTful GateWay with lambda on top legacy api. Easier Usage.

%Scheduled Services

%Bots and Skills

%next\cite{lambdaAWS}
%Shuttdown untagged EC2 instances. 

%Code Deploy

%Process inbount mail: attachment to S3 + link to it spam filter

%Detect expiring certificates

%Betriebsystemabhängigkeiten erkennen: Traditionellen Computing wie EC2, wo die Entwickler root  hat, in Lambda ist diser Opaque.

%OS Attribute Konfigurationen: Priorisieren CPU, GPU, Networking, or Disk Speicher und Geschwindigkeit. In Lambda skalieren proportional.

%Sicherheit: Lambda nicht sichtbar host-based intrusion detection systems cannot be installed, system-level access logs

%Dauerhafte Prozesse. Lambda kann bis 300s. Kosten pro Monat 1Gb  Lambda = 37 EC2 = 9Dollar. Wenn warten auf Requests, oder auf Callbacks geht nicht.

%\paragraph{CloudSearch}
%\begin{wrapfigure}{i}{0.16\textwidth}
%	\includegraphics[width=0.9\linewidth]{./pics/aws/Analytics_GRAYSCALE_AmazonCloudSearch.eps}
%\end{wrapfigure}

%\paragraph{CloudFront ( CDN )}
%\begin{wrapfigure}{i}{0.16\textwidth}
%	\includegraphics[width=0.9\linewidth]{./pics/aws/NetworkingContentDelivery_GRAYSCALE_AmazonCloudFront.eps}
%\end{wrapfigure}

%\paragraph{DNS management ( Route 53 )}
%\begin{wrapfigure}{i}{0.16\textwidth}
%	\includegraphics[width=0.9\linewidth]{./pics/aws/NetworkingContentDelivery_GRAYSCALE_AmazonRoute53.eps}
%\end{wrapfigure}

%\paragraph{Caching (ElastiCache)}
%\begin{wrapfigure}{i}{0.16\textwidth}
%	\includegraphics[width=0.9\linewidth]{./pics/aws/Database_GRAYSCALE_AmazonElasticCache.eps}
%\end{wrapfigure}

%\paragraph{Elastic Transcoder}
%\begin{wrapfigure}{i}{0.16\textwidth}
%	\includegraphics[width=0.9\linewidth]{./pics/aws/ApplicationServices_GRAYSCALE_AmazonElasticTranscoder.eps}
%\end{wrapfigure}



%\paragraph{Cognito}
%\begin{wrapfigure}{i}{0.16\textwidth}
%	\includegraphics[width=0.9\linewidth]{./pics/aws/MobileServices_GRAYSCALE_AmazonCognito.eps}
%\end{wrapfigure}


%Foo bar ist \lstinline|f = 2 + 2| wasd asdf 

%\section{Technologien}
%Microsoft Azure Funktions 
%AuthO : AuthO
%Firebase : Google
%Stack Driver Logging : Google
%Cloud Machine Learning Engine : Google
%Cloud DataFlow : Google -> Stream batch pipelines
%Big Query : Google




%Befehlmuster wird bei Fusekiserver\ref{komponenten:fuseki} als erteiler der Httpanfrage indem die SparQL Abfrage weiterleiten kann. Daher wird ein Pfad haus/hunde und haus/katze zur gleichen Funktion führen.
%Dieser kann aber offline gehen, also mehreren priorisierten MessagePattern als Queue vor eine oder mehreren Lambdas zu setzen absichert die Stabilität des Systems und entkoppelt Komponenten @RoundRobin?? BSRN.
%Die Verkettung von Funktionen mittels \glqq Pipes\grqq erlaubt die mehrfache Filterung von Daten.

%\section{Guidance}
%Caching -> Lambda Reads Same source and Process
%Compute partitioning -> Lambda per use. solved
%Data Consistency -> Embrace Eventual Consistency in Distributed DBs
%Data partitioning <-> Sharding 
%Instrumentation and Telemetry Guidance -> Errors Handling
%Service Metering -> understand future use of services
